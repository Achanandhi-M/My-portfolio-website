[{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. I am back with exciting news and an announcement from AWS re:Invent 2023.\nIf you are coming across the AWS re:Invent event for the first time, note that it is one of the largest cloud computing events in the world. AWS customers, partners, developers, and cloud enthusiasts gather to learn about the latest advancements in cloud technology, share experiences, and network with others in the industry.\nThis event occurs annually; this time, the event happened in Las Vegas. There are many new AWS Services announced in the fields of Machine Learning, Storage, Compute, Analytics, etc.\nAmong these announcements, my favorite one is Amazon Q (A new generative AI-powered assistant).\nAmazon Q can help business users complete tasks using simple natural language prompts. Apart from business tasks it also helps us in learning AWS services. The best part about Amazon Q is it can also be useful for troubleshooting and solving issues directly in the console.\nAmazon Q Trained on 17 years of AWS knowledge and best practices, Amazon Q is designed to help you at each stage of development with a new experience for building applications on AWS. You can also use Amazon Q to write code for your simple web applications, and you can ask Amazon Q to suggest the best and cost-optimized AWS services for hosting simple web Applications, based on your request it will suggest the service.\nIn our next blog, we will be seeing how we can integrate Amazon Q in our VS code Environment. Stay engaged with me for upcoming re:Invent announcements that I\u0026rsquo;ll be sharing.\nRegards\nAchanandhi M👦\nReferences:\nhttps://aws.amazon.com/blogs/aws/amazon-q-brings-generative-ai-powered-assistance-to-it-pros-and-developers-preview/\nhttps://aws.amazon.com/blogs/aws/introducing-amazon-q-a-new-generative-ai-powered-assistant-preview/\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/reinvent/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. I am back with exciting news and an announcement from AWS re:Invent 2023.\nIf you are coming across the AWS re:Invent event for the first time, note that it is one of the largest cloud computing events in the world. AWS customers, partners, developers, and cloud enthusiasts gather to learn about the latest advancements in cloud technology, share experiences, and network with others in the industry.","title":"Amazon Q Rocks re:Invent 2023!🚀"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. We have already started the AWS for Newbies blog series, In our previous blog we saw about the Introduction to AWS and why we need to work with AWS.\nToday\u0026rsquo;s quote\n\u0026ldquo;Growth is not only about taking risks but moving beyond your present circumstances.🌱\u0026rdquo;\n- Jay Shetty\nToday Blog Agenda:\n**How can I get hands-on with AWS?**🛠️\n**Why is knowing the AWS Free Tier important?**💡\nSharing my AWS Free Tier registration experience💳🆓\nWhat\u0026rsquo;s next🌈🚀\nSummary🏁\n**How can I get hands-on with AWS?**🛠️\nLearning Theory alone can\u0026rsquo;t help us gain knowledge, we need to apply and test what we learn in that theory part. So gaining hands-on experience is so important. This is not only applicable to AWS, it is applicable to every domain including coding.\nQuestion: Gaining practical experience in the cloud isn\u0026rsquo;t as straightforward as some other fields and often involves expenses. How can I acquire real-world skills?\nAnswer: Every one of us will have the same questions when starting to work with the cloud. The best solution for this is to use the free tier account. By using a free tier account, we have the option to work with cloud services without paying money.\n**Why is knowing the AWS Free Tier important?**💡\nIf you are interested in working with AWS, you must know how to use the AWS free tier, knowing the AWS free tier is so important. It is the best option to start with working AWS services. AWS Free Tier enables you to gain free, hands-on experience with more than 60 products on AWS\nUse this link to explore the AWS free tier https://aws.amazon.com/free/.\nonce you land on the AWS free tier page, there are 3 types of offers available, please carefully watch the offers and use them accordingly.\nApart from all this, you can also filter the product, please carefully see the offers mentioned in the free tier to avoid unexpected costs. In the below image, under the product categories, I filtered the Compute services, There are 5 services available under Compute, which you can use accordingly.\nYou can see the details below for Amazon EC2 instances, which instances are eligible for the free tier. you can use those particular instances for your workloads, in case you spin up the instances which are not covered in the free tier, and you end up with the cost.\nNote:\nPlease Be aware while using the free tier, that if you mistakenly do anything you will end up with the cost. Have the courage and try something new. Verify the offers before using AWS services in the free tier, to avoid unnecessary costs.\nSharing my AWS Free Tier registration experience💳🆓\nI am an AWS Enthusiast, I want to learn AWS and also I want to gain hands-on experience. I was stuck and I had no idea about the hands-on part, I know enough theory, but I need to work on my ideas. After all the research I found the AWS free tier, but I was afraid to use it, because we need to register through our credit card, if anything goes wrong we need to pay, so first I was afraid to register, at the same time I have no other choice apart from free tier, after all, confusion I came to a point. Ok, If I am not well enough to pay, I will not become a Cloud Engineer or DevOps Engineer. I want to go to AWS Magic World (AWS Console), and for that, I want to be bold, and I need to have courage, I developed that attitude. It takes me four days to get an AWS free tier because I had an issue with my bank, probably you will get it in a single day. After facing all struggle I got my AWS Account on 29 July 2023. My goal is to experiment with all AWS services given in the free tier, I am working on that. I hope I will complete my goal.\nWhat\u0026rsquo;s next🌈🚀\nThis blog is just an introduction to AWS Free tier, In the next blog, we will focus on, how to create an AWS free-tier account, how to create a virtual server, etc.\nSummary 🏁\nLet\u0026rsquo;s keep up the enthusiasm and explore the real power of AWS in our upcoming blog. See you in the next blog. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/aws-for-newbies-01/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. We have already started the AWS for Newbies blog series, In our previous blog we saw about the Introduction to AWS and why we need to work with AWS.\nToday\u0026rsquo;s quote\n\u0026ldquo;Growth is not only about taking risks but moving beyond your present circumstances.🌱\u0026rdquo;\n- Jay Shetty\nToday Blog Agenda:\n**How can I get hands-on with AWS?**🛠️\n**Why is knowing the AWS Free Tier important?","title":"AWS for Newbies-01🦋"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. We are going to start the AWS Learning series, we have already seen the Docker series and other Blogs related to Machine Learning and Local Stack. From this blog onwards we are focusing on AWS. This blog is for absolute beginners who are starting their AWS Journey. Don\u0026rsquo;t worry we are going to start from scratch.\nToday\u0026rsquo;s quote\n\u0026ldquo;Dream big. Start small. Act now.🌟\u0026rdquo;\n- Robin Sharma\nToday Blog Agenda:\nWhy AWS❓🤔\nHow to Start Learning AWS❓🤔\nWhat\u0026rsquo;s next🌈🚀\nSummary🏁\nWhy AWS❓🤔\nI think Everyone knows about AWS, At least we have heard about AWS. AWS is the most widely used Cloud platform, and AWS has a huge market share in the industry, apart from AWS provides more services(200+) than other cloud providers. AWS provides services for all kinds of use cases from Compute to Blockchain, Quantum computing, Machine Learning, etc. From my perspective, if we learn AWS, we have great career options in the future. I think every company is moving from on-premises to Cloud. Learning Cloud is the best option.\nHow to Start Learning AWS❓🤔\nOkay, Now you\u0026rsquo;re interested in learning AWS, but still confused about taking your first step in Learning AWS right? Don\u0026rsquo;t worry you are not alone, even I also had the same questions when I was starting to learn about AWS. Below are some of the questions that probably everyone has.\nQuestion 1: I have zero knowledge of Cloud computing, is it easy to start learning AWS?\nAnswer: yes, you can, once you start learning AWS probably you will learn the concepts of cloud computing as well.\nQuestion 2: I am from a non-technical background, is it possible for me to learn AWS?\nAnswer: yes, you can, Anyone can start learning AWS, One thing most important is you need interest and passion. If you are interested and passionate about AWS then the sky is the limit.\nQuestion 3: Resources for Learning AWS?\nAnswer: There are many resources available for learning AWS, AWS also provides many resources like Skill builder platforms which provide 650+ free courses for learning AWS Services, also AWS provides a documentation section for working with AWS Services.\nQuestion 4: How to get hands-on experience?\nAnswer: Many people often ask about getting hands-on experience with AWS because theory alone provides limited knowledge. Real understanding and practical use cases come from working with the services. While there are limited free options, the AWS Free Tier account is a great starting point. Additionally, AWS Cloud Quest, which is free and offers a game-based cloud challenge for cloud practitioners, can be both fun and educational. It\u0026rsquo;s one of the best ways to kick-start your journey with AWS.\nQuestion 5. There are 200+ services, is it necessary to learn about those 200+ services?\nAnswer: From my perspective, is it not necessary to learn those 200+ services, You can learn if you are interested. There are 4 main pillars and the most commonly used services like _compu_te, Storage, Networking, and Databases. If you are a beginner who started learning AWS, you can just focus on those 4 pillars of services.\nIf you have any questions apart from those I mentioned, please free to mention them in the comment section.\nWhat\u0026rsquo;s next🌈🚀\nThis blog is just an introduction to AWS, In the next blog, we will focus on the hands-on part, how to create an AWS free-tier account, how to create a virtual server, etc.\nSummary 🏁\nLet\u0026rsquo;s keep up the enthusiasm and explore the real power of AWS in our upcoming blog. See you in the next blog. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/aws-for-newbies/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. We are going to start the AWS Learning series, we have already seen the Docker series and other Blogs related to Machine Learning and Local Stack. From this blog onwards we are focusing on AWS. This blog is for absolute beginners who are starting their AWS Journey. Don\u0026rsquo;t worry we are going to start from scratch.\nToday\u0026rsquo;s quote\n\u0026ldquo;Dream big. Start small. Act now.🌟\u0026rdquo;","title":"AWS for Newbies🦋"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. This blog is the continuation of our Docker Dreams learning series. We learned a little about containers and docker in our previous docker-related blogs. Today we will see about Docker Hub_(a place where we store our images)._\nIn this Blog:\nWhat is Docker Hub? Why do we need it❓🤔\nHow to publish your own image to Docker Hub❓🤔\nDemo part ⛵️🚀\nWhat next?🌈🚀\nSummary🏁\nWhat is Docker Hub? Why do we need it❓\nDocker hub serves as a repository where developers can store, share, and distribute container images. we already know about the container images which contain everything needed to run a piece of software, including the code, runtime, libraries, and system tools. Docker Hub provides a central location for developers to find and use pre-built container images, streamlining the process of packaging and deploying applications in containers.\nDocker Hub is a concept more likely related to GitHub. we use GitHub for project collaboration with multiple developers who are working on the projects. The same concepts are used here we are using Docker Hub for storing our container images, and GitHub for storing our code. In both concepts, we can use the version control method.\nHow to publish your own image to Docker Hub❓🤔\nPublishing our images to Docker Hub is not rocket science, we can easily push our image to Docker Hub in just two commands. Before publishing, we need to create an account in Docker Hub.\nIf you don\u0026rsquo;t have an account use think link https://hub.docker.com/signup to signup\nOnce you created an account, it some how look like this\nOnce you log in you don\u0026rsquo;t see any repository, but in the above image, there are two images are there which were created by myself.\n**Note:**⚠️\nDocker Hub offers two kinds of service community edition and pro edition, the difference between them is in the Pro edition we have the option to store our images privately, but in the community edition, we also have the option to store one image private, we need to store our image public in the community edition. Choose the option based on your use case.\nDemo part ⛵️🚀\nI think we have seen enough theory, it\u0026rsquo;s time to get our hands dirty.\nsudo docker images #use to list the images You can also build your own application in the image and push that image into Docker Hub, and once it is uploaded anyone can pull it and use it on their own local machine. I am using my own image for the demo part\ndocker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] sudo docker tag nginx:alpine achanandhi/nginx:alpine Before pushing the image into the docker hub you need to tag the image.\nsudo docker login #login into docker hub Once you enter the command it will ask you to enter the credentials (email id and password) once you enter the credentials it will log in successfully, the output somewhat looks like this:\nsudo docker push achanandhi/nginx:alpine Once you enter the command, it will push your image from the local computer into the docker hub repository.\nBoom.. we successfully pushed our image, let\u0026rsquo;s see in the Docker hub repository\nOur docker image is successfully uploaded into the docker hub.\nWhat next?🌈🚀\nOur next target is focusing on cloud providers, and how we use the cloud services related to containers(ECS, Google Cloud run Azure Cloud Instances).\nSummary🏁\nIf you have any doubts, please mention them in the comment section. Let\u0026rsquo;s keep up the enthusiasm and explore the real power of Docker in our upcoming blog. See you in the next blog. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/docker-dreams-4/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. This blog is the continuation of our Docker Dreams learning series. We learned a little about containers and docker in our previous docker-related blogs. Today we will see about Docker Hub_(a place where we store our images)._\nIn this Blog:\nWhat is Docker Hub? Why do we need it❓🤔\nHow to publish your own image to Docker Hub❓🤔\nDemo part ⛵️🚀\nWhat next?🌈🚀\nSummary🏁","title":"Docker🐬 Dreams💭-4"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. This blog is different from all of my previous blogs, In this blog, we are going to interact with ChatGPT locally on our machine. Let\u0026rsquo;s get started:\nToday\u0026rsquo;s blog agenda:\nMy reflections regarding ChatGPT.\nKeep these points in mind.\nInteract with ChatGpt using API\nSummary.\n1. My reflections regarding ChatGPT.\nChatGPT has revolutionized the field of Artificial Intelligence. I think everyone used it, it is awesome. I was so impressed, I have no words to describe it. Everything was fine for me, but one thing I was not happy with about OpenAI(The entity responsible for developing ChatGPT) is that the GPT model(GPT 3.5 and GPT-4) is not Open source (which means the code is not available to open, it is like a proprietary software like windows).\nThere are two features available as we know, GPT3.5 and GPT-4. GPT3.5 is free to use, for GPT-4 you need to pay $20/month. Till now I have used ChatGPT On their website. But once came to know their API called OpenAI API( it\u0026rsquo;s a powerful tool kit to interact with OpenAI Large Language Model called GPT-3.5 and GPT-4). Let\u0026rsquo;s see How we interact with that model.\n2. Keep these points in mind.\nThere are a few things we need to consider before getting started with using OpenAI API keys.\nPlease note that OpenAI currently offers a $5 credit for new users, allowing you to start experimenting with their APIs at no cost. This credit is available for use during the first 3 months of your account. After the initial 3-month period, the pricing will transition to a pay-as-you-go model.\nMake sure to securely store your Secret Key in a permanent location; it will only be visible during the creation process.\nDon\u0026rsquo;t worry I think $5 credit is more than enough are testing smaller kinds of stuff.\n3. Interact with ChatGpt using API\nVisit the OpenAI website to get started click on me\nOnce you land, Click API Section to get started with OpenAI API Click here\nYou can see the Documentation, API Reference, Examples, and playground feature to play around with ChatGpt. once you log in you can see your account details in the right corner. There are many options available click view API key options.\nI created a API key for Interaction with ChatGPT\nOnce you created your API Keys, Let\u0026rsquo;s dive into coding parts, Don\u0026rsquo;t worry about coding parts, it is simple and written in Python, so you easily understand them.\nplease install the OpenAI package, before get started #pip install openai import openai #Enter your API key it start with sk openai.api_key = \u0026#39;sk-\u0026#39; def task(): #In the prompt section give you question what ever it might be prompt = \u0026#39;who is the founder of jainism\u0026#39; response = openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;who is the founder of jainism.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;\u0026#34;} ] ) print(response.choices[0][\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;]) if __name__ == \u0026#39;__main__\u0026#39;: task() The output will be like this\nHow fascinating is this right?, The output is generated by the GPT 3.5 model, but this time we do not use their website, instead you used API to interact with the model, which is the best way to use ChatGPT.\nplease modify the prompt to get a different output, in case you face any issues Please mention that in the comment section.\n4. Summary\nThis is just the beginning we can do a lot more stuff by using ChatGPT API keys, In the future we can see many projects and blogs related to LLM and Generative AI. If you find it useful please share it with your friends and let others also make use of it. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/chatgpt-in-your-local-machine/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu. This blog is different from all of my previous blogs, In this blog, we are going to interact with ChatGPT locally on our machine. Let\u0026rsquo;s get started:\nToday\u0026rsquo;s blog agenda:\nMy reflections regarding ChatGPT.\nKeep these points in mind.\nInteract with ChatGpt using API\nSummary.\n1. My reflections regarding ChatGPT.\nChatGPT has revolutionized the field of Artificial Intelligence. I think everyone used it, it is awesome.","title":"ChatGPT in your Local Machine"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have already seen the Introduction to LocalStack in our previous blog. LocalStack is a tool that runs on your local machine that emulates AWS API. Now in this today\u0026rsquo;s blog, we are going to explore and learn about LocalStack. The below image shows the working of LocalStack.\nImage credit: KodeKloud\nToday\u0026rsquo;s Agenda:\nHow to install LocalStack on your local machine🤔?\nAWS Services on LocalStack\nHow to integrate LocalStack?\nSummary\n1. How to install LocalStack on your local machine🤔?\nThe first thing I want to mention here is that there is no management console, likewise, we see in AWS Management Console, In LocalStack everything we will be working with the command line.\nMy best choice for learning or for the installation of any service, I will prefer documentation. Documentation is the best part of getting started.\nThe below image shows the LocalStack Installation Docs\nUse documentation for installation purposes. There are multiple ways you can install LocalStack, it depends on your use case. you can install a LocalStack based on your platforms, apart from there are different ways you can install LocalStack, you can install by using LocalStack CLI, docker,docker-compose, and also using helm. Choose the one that best suit for your use case. Remember LocalStack runs on a docker container. I installed LocalStack using docker.\n2. AWS Services on LocalStack\nLocalStack provides emulation services for different AWS APIs. Almost every service is available in LocalStack, you can use Services like S3, Lambda, IAM, ECR, EC2, EKS, etc. But the issue is here is you can\u0026rsquo;t use EKS for Community Edition, and for that, you need to pro user. Don\u0026rsquo;t there are other Services you can use for testing purposes? Here is the list of services LocalStack offers.\n3. How to integrate LocalStack?\nNow it\u0026rsquo;s time for making our hands dirty, get ready with your command line. verify LocalStack is installed on your machine\nlocalstack --version localstack start LocalStack start will start the LocalStack docker container. If you got similar output like this, you are on the correct path, if not you need to evaluate and try to fix the issue. If are unable to fix it please post in the comment section. It is better to use to sudo in front of the LocalStack command.\nIntegrations\nNext, open the new tab in the terminal, don\u0026rsquo;t use the same tab where you ran the initial start command. Next, steps are the most important step in working with LocalStack, you need to integrate LocalStack to use cloud resources. Switch to the Integrations page:\nThere are multiple ways you can integrate based on your needs, we are now focusing mainly on the AWS Command line interface, it is a very important integration, it will only send the incoming endpoint to LocalStack instead of sending it to AWS. Don\u0026rsquo;t forget to integrate, otherwise, you will not get the desired output.\nClick the AWS Command line interface in the left-side menu\nIn the overview section, there are two CLI alternatives, they both will give the same result.\n(i) AWS CLI Setup\nIf you want to use AWS CLI you can follow this one, and also forget to read the Note. Use the \u0026ldquo;test\u0026rdquo; as a value for aws_access_key and for aws_secret_key. Don\u0026rsquo;t forget to change or include the endpoint URL, the endpoint URL is used to divert the request to the LocalStack endpoint instead of sending it to AWS.\n(ii) LocalStack AWS CLI\nLocalStack AWS CLI is created by Localstack, for interacting with locally created services through API. I prefer to use to LocalStack AWS CLI it best way to get started. You can what best suits you, both are the same\n4. Summary\nIn this blog, we installed LocalStack locally on our machine and we configured the endpoint URL to divert the request to LocalStack ie (integrations). Don\u0026rsquo;t forget to integrate it is a very important process. We have already seen enough theory, In our upcoming LocalStack blog we see, how actually we work with AWS services locally using LocalStack. In the next blog, we see how to work with S3 locally. See you in Next Blog. If you find it useful please share it with your friends and let others also make use of it. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/getting-started-with-localstack/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have already seen the Introduction to LocalStack in our previous blog. LocalStack is a tool that runs on your local machine that emulates AWS API. Now in this today\u0026rsquo;s blog, we are going to explore and learn about LocalStack. The below image shows the working of LocalStack.\nImage credit: KodeKloud\nToday\u0026rsquo;s Agenda:\nHow to install LocalStack on your local machine🤔?\nAWS Services on LocalStack","title":"Getting Started With LocalStack"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have already started the Docker🐬 Learning series and the Introduction to LocalStack. This Blog is different from all of my previous blogs. In this blog, we are going to see how we can build and test our Machine learning model in AWS Cloud without using credit cards. I was super excited when I saw this first time, and also I am interested to share with you guys.\nToday\u0026rsquo;s Agenda:\nWhy do we need Cloud for ML Based workloads🤔**?**\nMachine Learning on AWS\nWhat is special about Amazon Sagemaker Studio Lab🤔**?**\nHow to get started with Sagemaker Studio Lab🤔**?**\nSummary.\n1. Why do we need Cloud for ML Based workloads🤔**?**\nBefore answering this, I want the reader to think or ask this question to themselves. why do I (you) need Cloud for my(your) ML projects? ok, I Know you got the correct answer, Let me explain my Thought on why I need Cloud for my ML-based projects.\nI don\u0026rsquo;t need to worry about hardware(CPU/GPU/TPU).\nI don\u0026rsquo;t need to worry about scalability\nI don\u0026rsquo;t need to worry about performance.\nI don\u0026rsquo;t need to worry about security\nPlease mention your thought on why you need cloud for your ML-based projects, please mention them in the comments section, Spread the word so that others can also become aware of this information.\n2. Machine Learning on AWS\nAs we all know AWS holds a dominant position in the realm of cloud computing. They are providing 200+ services, it is a huge number, right? They are 15+ services in Machine learning. One of my favorites is Amazon Sagemaker.\nAlmost AWS provides everything you want to work with Machine learning, the thing is that you want to choose the right service for your workloads.\n3. What is special about Amazon Sagemaker Studio Lab 🤔?\nFirst of all, I want to mention here is Amazon SageMaker Studio Lab and Amazon SageMaker are related but distinct offerings within the Amazon Web Services (AWS) ecosystem. Amazon Sagemaker is meant for working with real-world projects and for deployment purposes. But whereas Amazon Sagemaker Studio Lab is useful for testing and for educational purposes, the best thing about the Amazon Sagemaker Studio Lab is free to use.\nThere are many prebuilt models you can use for your project. The most fascinating thing about Amazon Sagemaker Studio Lab is:\nYou can use the CPU for up to 4 hours at a time with a limit of 8 hours in a 24-hour period. (FREE)\nYou can use GPU for up to 4 hours at a time with a limit of 4 hours in a 24-hour period. (FREE)\n4. How to get started with Sagemaker Studio Lab 🤔?\nHave you Compromised? Really I was Compromised when I saw it the first time, and I thought I really want to test it out. And I applied for using Sagemaker Studio Lab, It will ask a few questions, you have to wait at least for 5 business days to process your account when your account is ready they will send an email to activate your account. Boom, you step into the cloud to work with ML-based tasks. Remember it is only for testing purposes, we can\u0026rsquo;t able to deploy huge models into Sagemaker Studio Lab. One thing I noticed after I used Sagemaker StudioLab, it is like an exact clone of the Jupyter Notebook.\nThe difference is we used Jupyter Notebook on our local computer, but now with Sagemaker studio, we are using Jupyter Notebook in Cloud. I think we discussed enough theory, why are you waiting? Let\u0026rsquo;s Move to Cloud(Use Someone\u0026rsquo;s else Computer)\nLink for creating a Sagemaker Studio Lab click on me\nThe below image shows the Sagemaker Studio Home page, Explore the page and Click the request free account button.\nEnter the necessary details on the Request account page to activate your account\n5. Summary\nEven If you are not too specific to the ML field, don\u0026rsquo;t miss the opportunity, to create an account play with ML and almost importantly learning ML is the most valuable skill. That is all for today\u0026rsquo;s guy, In our next blog We will see one of the important, as well as fascinating, and trending technology nowadays none other Generative AI, I will show my first project on Generative AI and which was developed and tested in Sagemaker Studio lab. See you in Next Blog. If you find it useful please share it with your friends and let others also make use of it. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\nML Enthusiast\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/machine-learning-on-aws/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have already started the Docker🐬 Learning series and the Introduction to LocalStack. This Blog is different from all of my previous blogs. In this blog, we are going to see how we can build and test our Machine learning model in AWS Cloud without using credit cards. I was super excited when I saw this first time, and also I am interested to share with you guys.","title":"Machine Learning On AWS"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have already started the Docker🐬 Learning series, In my previous Blog⏮️ we saw about what is Dockerfile? and with Examples. Yeah, Docker is like an Ocean we need to learn a lot, we still have not yet covered the essential part, but here after we can\u0026rsquo;t focus only on Docker, instead, we\u0026rsquo;ll explore and experiment with other technologies. Hereafter we can focus more on AWS, LocalStack, Docker, and K8s. Trust me Guys, We can start from Scratch, I am also new to LocalStack, and I didn\u0026rsquo;t have any experience in working with LocalStack, so no worries let\u0026rsquo;s get started together.\nToday\u0026rsquo;s Agenda\nWhat is LocalStack? why do we need it?🤔\nis LocalStack is alternative to AWS?🤔\nis LocalStack only for AWS?🤔\nBonus Tips\nConclusion\n1. What is LocalStack? why do we need it?\nLocalStack is a Free and Open Source\nAccording to LocalStack Docs, LocalStack is a cloud service emulator that runs in a single container on your laptop or in your CI environment. With LocalStack, you can run your AWS applications or Lambdas entirely on your local machine without connecting to a remote cloud provider!\nIn simple terms, we can run AWS services in our Local Environment, without the need to pay a single dollar for using the service. We can get an exact clone of AWS in LocalStack, and see how amazing it is, we can use LocalStack for testing our cloud apps locally on our computers.\n_Why do we need it?_🤔\nThis Meme is just to Explain its purpose\nEveryone has this Question, why do we need LocalStack?🤔 See the basic problem the LocalStack solves is we can test our entire cloud apps locally, if we want to test in AWS cloud, we have to pay for them, And also it takes more time, so we don\u0026rsquo;t want that right, In LocalStack we can test our services within seconds or minutes. LocalStack provides major AWS Services like Lambda, S3, EC2, EKS, ECR, IAM, etc. Please check out the documentation link for other services. One thing I want to mention here guys, LocalStack is also using containers for providing our local cloud Environment.\n2 . is LocalStack is alternative to AWS❓\nOne thing I want to mention here guys, LocalStack and AWS has different use cases, don\u0026rsquo;t think LocalStack is an alternative to AWS. AWS is the king of the cloud computing world, there offers nearly 200+ services. LocalStack has use cases where u can develop and test the AWS cloud.\n_This Meme is just to show how powerful the AWS cloud_🚀\n3. is LocalStack only for AWS?\nCurrently, LocalStack supports AWS cloud only, I don\u0026rsquo;t know what about the other cloud, Maybe in the future they develop for other cloud providers as well. LocalStack: Your AWS Ally in Local Development.\nAs everyone knows AWS is updating their services every day, is any update happens in AWS services it will soon also replicate in LocalStack as well, Don\u0026rsquo;t Worry about that.\nOne thing I was so excited about LocalStack is Free and open source, apart from this it is free to use AWS Cloud Services, and it contains also pods feature for collaboration. Apart from that it can also as used as Iac(Infrastructure as a code) it also supports many Iac providers, for free of cost. Why not give it a try?\n4. Bonus Tips🌈\nThe Bonus trip is all about LocalStack Free Educational License, you can get access to all features on the community and professional edition of LocalStack. You heard that right? Just apply for it, if your Student and educators. Click this [link](http://Get access to all features on the community and professional edition of LocalStack.) to apply.\n5. Conclusion🏁\nIn Summary, LocalStack and AWS: Bridging Cloud Services with Local Innovation. That\u0026rsquo;s all about guys, we have seen more theory parts in this blog, and we will have more hands-on and get started with LocalStack in our Upcoming Blogs. If you have any doubts, please mention them in the comment section. Let\u0026rsquo;s keep up the enthusiasm and explore the real power of LocalStack in our upcoming blog. See you in the next blog. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/introduction-to-localstack/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have already started the Docker🐬 Learning series, In my previous Blog⏮️ we saw about what is Dockerfile? and with Examples. Yeah, Docker is like an Ocean we need to learn a lot, we still have not yet covered the essential part, but here after we can\u0026rsquo;t focus only on Docker, instead, we\u0026rsquo;ll explore and experiment with other technologies. Hereafter we can focus more on AWS, LocalStack, Docker, and K8s.","title":"Introduction to LocalStack"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have started the Docker🐬 Learning series, In my previous Blog⏮️ we saw about web servers and also a practical demonstration of running a web server inside a docker container.\nToday\u0026rsquo;s Quote:\n\u0026ldquo;Service to others is the rent you pay for your room here on earth🌎\u0026rdquo; - Muhammad Ali❤️‍🩹 Today\u0026rsquo;s Exciting Blog Agenda:\n**what is Dockerfile?**❓\nWhy Dockerfile Matters! 🤔\nLaunch Your Website with Nginx and Dockerfile! ⛵️🚀\nWhat\u0026rsquo;s Next in our Docker Journey?🌈🚀\nConclusion🏁\n1) What is Dockerfile❓\nAccording to the Docker doc,\nDocker can build🏗️ images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. I think it may sound like complicating let me explain in a simple diagram✍🏻\nDon\u0026rsquo;t get confused😕 whiling seeing the diagram, it is just a simple illustration we often experience when we visit the hotel. Let\u0026rsquo;s compare this with Dockerfile creation and Execution. How the user is giving an order to the waiter, so like as the same, the user creates Dockerfile in their system, and how the waiter gives the order to the chef for preparing the food the user is given, same likewise the Dockerfile instructs the Docker to create the image based on the command mentioned by the user, after the chef Finished cooking the waiter serves the food to the user, same like in Docker🐬 world, the Docker Engine builds the container based on the Image built in the previous step.\nRemember the Dockerfile does not contain any file Extension\nLet\u0026rsquo;s Compare the above example with this example\nI think the above example clearly explains the role of Dockerfile, In the Dockerfile u mention all of your stuff like Dependencies and libraries in the form of Commands. Apart from that, we can include environment variables in Dockerfile.\nIn summary, a Dockerfile is like a recipe that instructs Docker🐬 on how to build a Docker image, which is a self-contained package containing all the necessary ingredients (dependencies) and instructions to run your application in a consistent and portable manner, just like a well-prepared dish you order in a hotel. Dockerfile makes creating and sharing these recipes easy, allowing others to enjoy the same delicious meal (application) in their own containers.\nWhy Dockerfile Matters! 🤔 Dockerfile matters because it defines the steps to create Docker images, ensuring reproducibility, version control, simplified deployment, isolation, and scalability for containerized applications.\nLaunch Your Website with Nginx and Dockerfile! ⛵️🚀 Let\u0026rsquo;s see a practical demo, we are going to see the same example as we saw in our previous blog, but the difference is that we are not going to manually go to deploy this, we are doing by this creating a very very simple Dockerfile\nFollow the below steps below to do\nmkdir nginx-demo-Blog #create separate Directory cd nginx-demo-Blog vi Dockerfile # Create Separate Dockerfile vi myWebPage.html #Create html file I think the above Dockerfile📁 is very simple because it will not contain that many commands in Dockerfile, Dockerfile contain only Two commands FROM and COPY commands, FROM Command, is used to mention the base image which we are going to use in our later part, and the COPY command is used to COPY the files to a directory inside the container. We will see more commands and complex Dockerfile in a later blog.\nThis is our HTML file [myWebPage.html] or you can use your own Html file please feel to modify\ndocker build -t[tag] \u0026lt;image-name\u0026gt; docker build -t nginx:alpine . Remember ⚠️to include \u0026ldquo;.\u0026rdquo; at the end of the docker build command, When you run the docker build command with the \u0026ldquo;.\u0026rdquo; (dot) at the end, it tells Docker to search for the Dockerfile in the current directory. Docker will use all the files and directories in the current directory as the build context\nThe docker build command is used to build our Docker image based on the instructions we mentioned in our Docker file. The output shows the image is built successfully.\nAgain, We need to cover a lot about Image layers, which is one of the important concepts in the Dockerfile concepts, we focus a lot more in the next blog.\ndocker images Use the docker images command to verify the image present in our system.\nWe successfully 🚀💪built our image by ourselves using our own Dockerfile, We need to create a container for our image using this command\ndocker run [options] \u0026lt;container-name\u0026gt; \u0026lt;image-name\u0026gt; docker run -d -p 84:80 nginx-webpage nginx-alpine The -p command is used to expose what we saw in our previous blog, I think we need to ask ourselves what these numbers denote 84:80 ?? 84 is the port number of the host side which we enter in the browser along with the Ip address , 80 port number denote the container port\nHow we can make sure that we deployed successfully❓😕\nUse this command\ndocker exec -it nginx-webpage sh The above output shows we deployed in the correct directory\nOur Output Looks like this:\nhttp://yourIpAddress:portNumber/fileName If you got this output 😂😅 Yeah we Successfully deployed our web page into the Nginx web server using Dockerfile, If your creating your own web page make sure that you got correct the output, if not please mention it the in comments section\nWhat\u0026rsquo;s Next in our Docker Journey?🌈🚀\nIn our next blog, we can deep delve into docker concepts and also we can see some more examples.\nConclusion🏁\nIf you have any doubts, please mention them in the comment section. Let\u0026rsquo;s keep up the enthusiasm and explore the real power of Docker in our upcoming blog. See you in the next blog. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/docker-dreams-3/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have started the Docker🐬 Learning series, In my previous Blog⏮️ we saw about web servers and also a practical demonstration of running a web server inside a docker container.\nToday\u0026rsquo;s Quote:\n\u0026ldquo;Service to others is the rent you pay for your room here on earth🌎\u0026rdquo; - Muhammad Ali❤️‍🩹 Today\u0026rsquo;s Exciting Blog Agenda:\n**what is Dockerfile?**❓\nWhy Dockerfile Matters! 🤔\nLaunch Your Website with Nginx and Dockerfile!","title":"Docker🐬 Dreams💭-3"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have started the Docker🐬 Learning series, In my previous Blog⏮️ we saw about docker images and containers with real examples.\nToday\u0026rsquo;s Exciting Blog Agenda:\n**Web Servers: Your Website\u0026rsquo;s Backbone!**🦴\nRunning a Web Server Inside a Container🐬\nExposing Your Website to the World! 🌐\nWhat\u0026rsquo;s Next in our Docker Journey?🌈🚀\nConclusion🏁\n**Web Servers: Your Website\u0026rsquo;s Backbone!**🦴 Before we delve into web servers, we first need to understand what is the server? Don\u0026rsquo;t get overwhelmed😵 when you hear the term server, see basically server is a computer💻 only, the server has high computing power and memory resource than our normal machines. Our normal computer is designed for small use cases, but servers are meant for high-performing tasks💪. The main purpose of the server is to provide service, Hmm\u0026hellip;..what kind of service?🤔 The service depends on the use case if the server belongs to a web server, then the server serves websites, if the server belongs to a file server like FTP, it stores and manages files related to the client, if the server belongs to email server then it belongs to provides service related email, so they are many servers, the main goals of these servers is to provide service to the user with zero downtime.\nIn Simple terms,\nServer: A computer or system that provides services or resources to other computers or devices on a network.\nWeb Server: A specialized server that stores and delivers website files to users\u0026rsquo; web browsers when they access a website on the internet.\nProblems with physical data centers servers\nBut when we are talking about servers, we need to consider one important factor maintenance, Maintenance ? for what? For server only, Server is like our computer, But It is a big computer, and it needs to run continuously 24X7 for providing service to the user, Thing in the way if my server is running 24X7 it needs a continuous power supply, a separate person to monitor the performance of the server if my server is down or crashed my user will not get the service, so separate person needs to monitor the health of the user, Now we are dealing with a single server, but what happens when our user is increased?⬆️ our single server is not able to handle the request from a user, so we need an additional server when our user base is increasing. See on the flip side we purchased 100 servers due to an increase in userbase, what happens when unfortunately the userbase is decreased, our 100 purchased server is a waste, our purchasing cost is a waste, and our human resources is a waste in this situation.\nOnly one solution for the above problem is to migrate to the cloud,☁️ It will take care of you. Again this is a separate topic we will cover in another blog, I have already written blogs related to the cloud, if you want to know check it out.\nRunning a Web Server Inside a Container🏃‍♂️\nNow we focus on how to run our web server in our docker container. One thing I want to mention here is that you don\u0026rsquo;t need to purchase any server or don\u0026rsquo;t want to set up any server in the cloud or on-premises for this example, because we are testing in our local system as a local host, running our web server locally does not require any requirements, you just need to install web server like Apache or Nginx, these two web servers are most popular and both are open source.\nIn our previous example, we ran hello world using hello-world docker image, the same methodology here, first, we need to pull the image and we want to run the container using that image, and finally, we want to expose the container that\u0026rsquo;s all.\nLet\u0026rsquo;s start by identifying our end goals, what is our end goal guys? we need to run a web server inside a docker container, so we need to pull the image related to a web server in this case either Apache or Nginx, you can choose either one based on your use case. For this example, we use Nginx as our web server.\nUse this command to pull the Nginx web server\ndocker pull nginx we have successfully pulled the nginx image from the Docker hub, Next check it once we have that image by typing the command\ndocker images Next we have create an isolated environment (container) for running our Nginx image By using the command\ndocker run -d -p 80:80 --name nginx-container nginx Here \u0026ndash;d flag is used for running a container in a detached mode which means running in the background, \u0026ndash;name flag is used to name a container, we can give any name to a container, but remember two containers should not have the same container. The -p flag which I will mention in later part of this section.\nNext, we have to deploy our web page to the nginx web server, there are two ways we can do it, one by the manual method that is we deploy our webpage in the nginx directory, and another one is my favorite method is by automating the deployment process while building the docker image itself by using Dockerfile. But now in this, we see the first method and the second we will see on Next blog.\nThere is a separate command to enter into the docker container, the directory that is also present inside the docker container.\ndocker exec -it nginx-container sh Here exec is a Docker sub-command that allows you to run a command inside a running container, -it these are options used together to make the execution interactive. The \u0026ldquo;-i\u0026rdquo; option enables interactive mode, and the \u0026ldquo;-t\u0026rdquo; option allocates a pseudo-tty, which provides a terminal-like interface for interaction, nginx-container is the name of the container and finally sh is command we want to run inside the container. In this case, we are specifying \u0026ldquo;sh,\u0026rdquo; which starts an interactive shell session in the container.\nHere is the directory path where we want to deploy our webpage: /usr/share/nginx/html\nWe are now inside the docker container, the shell session is open inside the docker container, and we need to deploy our webpage inside the directory which I mentioned in above.\nWe are now inside the directory, we need to deploy our webpage in this directory, we need something called a text editor because if are manually deploying means we need a text editor for coding and deploying in that directory, I use Vim use can also use emacs or nano other as well as.\napt-get update #for updating the installed packages apt install vim #for installing vim text editor vim hello.html #you can give any name for your html file vim is a command used to open the Vim text editor following our file name.\nOnce u typed vi hello.html the blank page will open you can write your code in that and once you finished press the ESC button and type wq for saving your file.\nOnce finished we can check by typing ls command\nBoom, We successfully deployed our webpage inside the nginx web server which is running in a docker container. By default the docker container is not accessible outside the docker network, then how we can access our web page deployed in the Nginx web server?\nExposing Your Website to the World! 🌐\ndocker run -d --name -p 80:80 nginx-container nginx we previously used this command for creating an instance of our image, there I didn\u0026rsquo;t mention the -p flag, I think it is the correct place to explain. If you want to make a Docker container accessible from outside the Docker network, you need to explicitly publish the container\u0026rsquo;s ports to the host system using the -p option when running the container. This process is known as port mapping or port forwarding. By doing this, you can access the exposed ports of the container through the host system\u0026rsquo;s IP address or hostname. That why we need -p to mention in the command.\nhttp://yourHostIpaddress/yourFileName http://192.168.174.128/hello.html Wow, We have done it congratulations we have successfully deployed and accessed our webpage. If you got it error like \u0026ldquo;This site can’t be reached\u0026rdquo; we accessing, sorry you made a mistake, please cross-check it, surely u will get it. If you are struck and getting error means , please free to mention it in a comment section , I will surely help you.\nWhat\u0026rsquo;s Next in our Docker Journey?🌈🚀\nIn our next blog, we can see the same example by automating the deployment process by using Dockerfile.\nConclusion🏁\nIf you have any doubts, please mention them in the comment section. Let\u0026rsquo;s keep up the enthusiasm and explore the real power of Docker in our upcoming blog. See you in the next blog. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/docker-dreams-2/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have started the Docker🐬 Learning series, In my previous Blog⏮️ we saw about docker images and containers with real examples.\nToday\u0026rsquo;s Exciting Blog Agenda:\n**Web Servers: Your Website\u0026rsquo;s Backbone!**🦴\nRunning a Web Server Inside a Container🐬\nExposing Your Website to the World! 🌐\nWhat\u0026rsquo;s Next in our Docker Journey?🌈🚀\nConclusion🏁\n**Web Servers: Your Website\u0026rsquo;s Backbone!**🦴 Before we delve into web servers, we first need to understand what is the server?","title":"Docker🐬 Dreams💭-2"},{"content":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have started the Docker🐬 Learning series, In my previous Blog⏮️ we saw about how to install docker on our local system and we saw some basic docker commands.\nToday\u0026rsquo;s blog agenda:\nUnderstanding Docker Images and Containers😎\nUnleashing the Power of Docker💪\nDiscover Dockerhub: An Abundance of Useful Resources💫\nWorking with Docker Images and Containers: Real-Life Examples⚒️\nWhat\u0026rsquo;s Next in our Docker Journey?⏭️\nConclusion🏁\nUnderstanding Docker Images and Containers😎 Before working with Docker🐬 it is crucial to understand the concepts of images and containers because they are essential in Docker. In my previous blog⏮️ we discussed containers, which are lightweight and run in an isolated environment. However, you may be wondering**, What are images and why do we need them to create Docker containers?** These questions have arisen as I learn about Docker.\nLet\u0026rsquo;s see the answer with the simple analogy of ordering🍽️ and cooking🍳 food, let\u0026rsquo;s relate it to Docker🐬\nImage: An image is like a menu in a restaurant🏨. It lists various dishes🍪 and provides details about the ingredients, cooking instructions, and presentation. Just like you choose a dish from the menu, in Docker, you select an image that represents a specific application or environment you want to run.\nContainer: A container is like a chef🧑‍🍳 who receives the order and cooks the food according to the selected dish from the menu. When you order a dish, the chef creates a separate cooking area and prepares the dish with the specified ingredients and cooking instructions. Similarly, when you create a container from an image, Docker sets up an isolated runtime environment where the application or processes defined in the image run🏃‍♂️.\nHere\u0026rsquo;s how the process works with Docker:\nImagine you\u0026rsquo;re in a restaurant that offers a wide range of dishes (images) on its menu.\nYou browse the menu and select a specific dish (image) that you want to order. For example, you choose a \u0026ldquo;Web Server\u0026rdquo; dish from the menu, which represents an image with all the necessary components to run a web server.\nYou place your order with the waiter, who acts as Docker in this analogy. You tell Docker to create a container based on the \u0026ldquo;Web Server\u0026rdquo; image.\nDocker takes the \u0026ldquo;Web Server\u0026rdquo; image (recipe) and sets up a separate cooking area, which is an isolated runtime environment (container).\nInside the container, Docker follows the instructions provided by the image and sets up the web server, installs the required software, and configures the necessary settings.\nThe container is now running, and your web server is ready to serve requests. Just like the chef cooking your food, the container is executing the processes defined in the image.\nThe container remains separate from other containers and the underlying host system, ensuring isolation and security.\nIf you need to run multiple instances of the web server, you can order multiple containers based on the same \u0026ldquo;Web Server\u0026rdquo; image, just like requesting multiple servings of the same dish .\nIn this analogy, Docker acts as the intermediary between you (the customer) and the chef (the container). It takes your order (image) and creates a separate cooking area (container) where the specified dish (application or processes) is prepared.\nIn Docker, containers are created from images. You cannot create a container without an image. An image in Docker serves as a template or blueprint that contains all the necessary instructions, dependencies, and files required to create and run a container. The image defines the environment and the processes that will run inside the container.\nSo, in summary, an image is a prerequisite for creating a container. The image provides the necessary instructions and dependencies, while the container is the actual running instance that is created based on the image.\n2. Unleashing the Power of Docker\nYou can use Docker for anything, For example, you can find Docker images for popular databases like MySQL, PostgreSQL, and MongoDB. There are also images for web servers like Apache HTTP Server and Nginx, programming languages like Python, Java, and Node.js, development frameworks like Ruby on Rails and Django, and many more.\nIn addition to specific software components, Docker images can also include custom configurations, scripts, or additional dependencies needed for your application to run properly.\n3. Discover Dockerhub: An Abundance of Useful Resources💫\nWe already know that images are important for creating a Docker container, which is useful for establishing an isolated environment. But where on earth are those images present? They reside in Dockerhub, the official website of Docker, where millions of Docker images are available. You can pull and push your Docker images to Dockerhub so others can make use of them.\nUse this link to visit the magical world of Docker click here\nThe above image shows the home page of the Docker hub, in the top right-hand side it shows my name because I created an account in the docker hub, In the Docker hub u can also host our own docker images and also there is the option of creating private repositories.\nThe above picture shows the images present in the Dockerhub, u can search the image based on your requirements. U have the option to filter out based on your operating system and Architecture.\n4. Working with Docker Images and Containers: Real-Life Examples⚒️\nAfter identifying the desired image for your application, you can easily use or pull that image from Docker Hub. Don\u0026rsquo;t worry, there is a command specifically for this purpose:\ndocker pull \u0026lt;image name\u0026gt; You can use this command to pull the Docker image from Dockerhub\nLets\u0026rsquo;s see with an example - Hello world🌏 in Docker\nGet ready for hand on open up your terminal and type these commands in your command line\ndocker run hello-world The hello-world is a pre-build image in the Docker hub, which displays hello world in the terminal. Wait, earlier I said if you want to pull any image you can use the docker pull command, but now I have not used it the reason for that is if you use the docker run command, It will check the image locally, if the image is not present in locally, it will automatically pull the image from docker hub and it creates the container for running, it is the real power of using docker run command.\nThe above picture shows the output, if you got the same output as me, congratulations🎉 we\u0026rsquo;ve done it. Don\u0026rsquo;t forget to use sudo before docker commands. I am using the(Ubuntu) Linux operating system, so I am using sudo the reason for that is using sudo with the docker commands is required when running Docker as a non-root user, as it allows the command to be executed with administrative privileges. Docker requires elevated permissions to access system resources and manage containers. Running Docker commands with sudo ensures the necessary privileges are granted, enabling successful execution of Docker operations.\nThe output shows the container is not running. By default, a Docker container will stop once the main process running inside the container completes its execution. This means that when the process specified in the Docker image\u0026rsquo;s entry point or command finishes running, the container will automatically stop.\ndocker run -d \u0026lt;image_name\u0026gt; However, you can override this default behavior by specifying additional options or configurations when running the container, such as using the -d flag to run the container in detached mode and keep it running in the background.\n**What\u0026rsquo;s Next in our Docker Journey?**⏭️\nCongratulations🎉 we successfully 💥deployed and run our first container, don\u0026rsquo;t lose the spark, there is much more to explore in upcoming blogs. In our next blog, we will see the different types of flags used in docker commands and some examples, but trust me you really like the example.\nConclusion🏁\nIf you have any doubts, please mention them in the comment section. Let\u0026rsquo;s keep up the enthusiasm and explore the real power of Docker in our upcoming blog. See you in the next blog. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/docker-dreams-1/","summary":"Hi friends🙋‍♂️ welcome back to Blogs-with-Achu, we have started the Docker🐬 Learning series, In my previous Blog⏮️ we saw about how to install docker on our local system and we saw some basic docker commands.\nToday\u0026rsquo;s blog agenda:\nUnderstanding Docker Images and Containers😎\nUnleashing the Power of Docker💪\nDiscover Dockerhub: An Abundance of Useful Resources💫\nWorking with Docker Images and Containers: Real-Life Examples⚒️\nWhat\u0026rsquo;s Next in our Docker Journey?⏭️\nConclusion🏁","title":"Docker🐬 Dreams💭-1"},{"content":"Hi friends, welcome back to Blogs-with-Achu, we have started the Docker🐬 Learning series, In my previous Blog⏮️ we saw Introduction to Docker and containers, Today in this blog we are Going to see Docker installation and working with some basic Docker commands.\nToday blog\u0026rsquo;s is all about :\nDocker Installation🏠\nDocker Desktop💻\nAlternative method-Sandbox☁️\nCheck Docker is Installed🫡\nBasic Docker Commands💥\nWhat\u0026rsquo;s Next⏭️\nQuiz🧾\nConclusion.🏁\nDocker Installation🏠..\nFor working with docker, we need to first install docker in our local system💻. The installation process will defer based on the operating system.\nStep 1: Use this Link docker.io for installation\nStep 2: After that, u will land in the Docker world\nStep 3: Install Docker based on your operating system, if you\u0026rsquo;re using Linux install based on your Linux distributions\nI think the Installation process is easy, I hope you have done that. If are facing any issues please mention them in the comment section.\n**Docker Desktop💻\n**Docker Desktop is a tool designed to simplify the development and deployment of containerized applications. It provides an easy-to-use graphical interface for managing Docker containers and images on your local machine, regardless of the operating system you\u0026rsquo;re using.\n**Alternative method-Sandbox**☁️\nThere is another alternative method, you can run docker without installing it in your local system, yes you heard that right. Yeah, you can run docker in the cloud (that\u0026rsquo;s like in a sandbox environment). They are many websites are providing a sandbox environment for absolutely free, you can use it.\nUse this link for Docker\u0026rsquo;s official sandbox Environment\nThere are many websites providing sandbox environments you can also try the codesandbox.io website\n**Problem with Sandbox Environment**😵‍💫\nThere are Several problems are there while working with a sandbox environment\nResource Limitations: Docker imposes resource limits on containers to ensure fair sharing of resources with the host system and other containers. However, these limits can sometimes restrict the sandbox environment\u0026rsquo;s capabilities, such as memory, CPU, or network access.\nContainer Lifecycle and Persistence: By default, Docker containers are ephemeral, meaning any changes made inside the container are lost when it\u0026rsquo;s stopped or restarted. This can be problematic when working with a sandbox environment that requires persistence.\nDebugging and Troubleshooting: Debugging issues within a Docker sandbox environment can be more challenging due to the isolation.\nThe sandbox environment is best suitable for testing purposes, it is not suitable for individuals who want to play hard with the docker\nCheck Docker is Installed🫡\nIf you installed docker locally on your system, you are already one foot ahead of learning docker, there are several way use can verify whether you installed docker in your local machine. Use this command to verify :\ndocker --version I am running docker inside Ubuntu, and it shows the current version of docker installed on your local machine.\nBasic Docker Commands💥\nThere are some basic docker commands you can use frequently when working with docker\n1. docker images command will display all images in our local system\ndocker images The lists of docker images in my local system.\n2. docker container ps -a command will display all container both excited and running.\ndocker container ps -a 3. docker container ps command will display the container which are running\ndocker ps In the above image, there is no container running in my local system, so it shows nothing.\nWhat\u0026rsquo;s Next⏭️\nIn the next blog, we deep dive into the docker images concept, how to pull images from the docker hub, and how to work with images and containers with examples.\nQuiz🧾\nConclusion🏁\nIf you have any doubts, please mention them in the comment section. Let\u0026rsquo;s keep up the enthusiasm and explore the real power of Docker in our upcoming blog. See you in the next blog. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/docker-dreams-0/","summary":"Hi friends, welcome back to Blogs-with-Achu, we have started the Docker🐬 Learning series, In my previous Blog⏮️ we saw Introduction to Docker and containers, Today in this blog we are Going to see Docker installation and working with some basic Docker commands.\nToday blog\u0026rsquo;s is all about :\nDocker Installation🏠\nDocker Desktop💻\nAlternative method-Sandbox☁️\nCheck Docker is Installed🫡\nBasic Docker Commands💥\nWhat\u0026rsquo;s Next⏭️\nQuiz🧾\nConclusion.🏁\nDocker Installation🏠..\nFor working with docker, we need to first install docker in our local system💻.","title":"Docker🐬 Dreams💭-0"},{"content":"Hi friends, welcome back to Blogs-with-Achu, we have started the Docker Learning series, In my previous Blog we have seen about Container, Today in this blog we are Going to see Docker, Yes you heard that right?😉 According to Stack Overflow Survey-2020, Docker is the #1 most wanted platform,#2 most loved platform, and #3 most popular platform.\nIn Today\u0026rsquo;s Blog:\nIntroduction to Docker🙂\nDifference between Container and Docker💫\nDocker Architecture🏗️\nwhat next?⏭️\nConclusion🏁\nIntroduction to Docker🙂\nDocker is an open-source platform that enables developers to automate the deployment and management of applications within lightweight, isolated environments called containers. It provides a consistent and efficient way to package, distribute, and run software applications, regardless of the underlying infrastructure.\nDifference between Container and Docker💫\n1) Docker is a popular platform that allows you to create and manage containers.\n2) Docker provides the tools and infrastructure to build and run containers, making it easier to package, distribute, and deploy applications consistently across different environments.\n1) Containers, on the other hand, are lightweight, isolated environments that package applications and their dependencies.\n2) Containers are the encapsulated units that hold applications and make them portable and isolated Docker vs Container\nIn simple terms✌️, Docker is like a shipping company that provides the platform and tools to package and deliver applications. Containers are like shipping containers used to transport goods. Docker uses containers to encapsulate applications, making them portable, isolated, and easily deployable across different environments.\nDocker Architecture🏗️\nBefore Learning Docker, Learning its Architecture is very important.\nIn simple terms, Docker architecture consists of three main components: the Docker client, the Docker host, and Docker images.\nDocker Client: The Docker client is the command-line interface (CLI) or graphical interface used to interact with Docker. It allows you to issue commands to Docker and manage containers, images, networks, and volumes.\nDocker Host: The Docker host is the machine where Docker is installed and runs. It can be a physical or virtual machine (e.g., a server or a developer\u0026rsquo;s computer). The host runs the Docker daemon, which is responsible for managing containers and handling Docker API requests from the client.\nDocker Images: Docker images are the building blocks of containers. An image is a lightweight, standalone, and executable package that includes everything needed to run an application, such as the code, runtime environment, libraries, and dependencies. Images are created from Dockerfiles, which define the steps to build the image. Images can be stored and shared in registries like Docker Hub.\nWhen you want to run an application using Docker, the Docker client communicates with the Docker daemon on the host. It sends commands to the daemon to perform actions like creating containers, pulling images, starting or stopping containers, and managing networks and volumes.\nThe Docker daemon then interacts with the host\u0026rsquo;s operating system and manages the creation, execution, and lifecycle of containers based on the instructions in the Docker images. Each container runs in isolation, with its own filesystem, processes, and network interfaces.\n**what next?**⏭️\nIn our upcoming blogs, we will learn how to install Docker on our local machine to prepare for hands-on experience. In the next blog, we will delve into Docker concepts such as Docker images, Docker containers, Docker Compose, and Docker volumes. We understand that learning Docker requires time and effort, and it cannot be mastered in a single day. Therefore, we need patience and a genuine interest to grasp the concepts effectively.\nConclusion🏁\nIf you have any doubts, please mention them in the comment section. I believe we have understood the concepts of containers and Docker. Let\u0026rsquo;s keep up the enthusiasm and explore the real power of Docker in our upcoming blog. See you in the next blog. Happy learning and happy reading! 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/docker-dreams/","summary":"Hi friends, welcome back to Blogs-with-Achu, we have started the Docker Learning series, In my previous Blog we have seen about Container, Today in this blog we are Going to see Docker, Yes you heard that right?😉 According to Stack Overflow Survey-2020, Docker is the #1 most wanted platform,#2 most loved platform, and #3 most popular platform.\nIn Today\u0026rsquo;s Blog:\nIntroduction to Docker🙂\nDifference between Container and Docker💫\nDocker Architecture🏗️","title":"Docker🐬 Dreams💭"},{"content":"Use Container for deployment\nHi friends, welcome back to Blogs-with-Achu! In today\u0026rsquo;s fast-paced technological landscape, containers have emerged as a powerful software development and deployment solution. If you\u0026rsquo;re interested in learning containerization, you don\u0026rsquo;t need any specific prerequisites.😁\nIn Today\u0026rsquo;s Blog:\nWhat is Container?🤔\nWhy it is so popular?🤔\nIs VM?☠️\nContainerization Technology💻\nSummary🏁\n**What is Container?**🤔\nA container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another.\nThis may sound complicated let\u0026rsquo;s see with an example, Imagine you and your friend are both software developers working on a project. You develop the code on your Linux operating system using a specific version of a database, let\u0026rsquo;s say MySQL 5. However, your friend works on a Windows machine and uses the latest version of MySQL.\nDuring development, everything works smoothly on your respective machines. The code and functionality are perfect. However, when it comes time to deploy the application to a production environment, problems arise. The application encounters compatibility issues when it\u0026rsquo;s deployed on a different server or operating system. The database version on the production server might not be the same as what you used during development, causing conflicts and errors.\nHere\u0026rsquo;s where containerization comes to the rescue. Think of containerization as a special box that contains not only your code but also all the necessary components for it to run correctly, including the specific database version. By using containers, you can package your application, along with the required database version and any other dependencies, into a self-contained unit. This is not only applicable to databases, any application can be containerized.\n**Why it is so popular?**🐬\nI think you might be guessed why it is so popular. Let\u0026rsquo;s see them 😉\nContainers have become popular due to their portability, scalability, efficiency, alignment with DevOps practices, compatibility with cloud-native technologies, and the robust ecosystem of tools and technologies that support containerization. Containers empower developers and operations teams to build, deploy, and manage applications more effectively, ultimately improving productivity, agility, and scalability in software development and deployment processes.\n**Is VM dead?**☠️\nI think why might be wondering which one is replaced by a container, it is nothing but a Virtual machine. VM is not actually dead, but it\u0026rsquo;s lost its popularity among developers.\nLet\u0026rsquo;s difference between VM and container\nContainers virtualize the operating system and provide an isolated runtime environment for applications within the host OS.\nVMs virtualize the entire infrastructure, including hardware, and enable the execution of multiple independent operating system instances on a single physical machine.\nSpecial software Hypervisor is useful for virtualizing the underlying infrastructure in virtual machines (VMs), providing hardware-level virtualization, and managing the allocation of physical resources to multiple VMs.\nDocker Engine is useful for containerization, providing a runtime environment and tools for building, running, and managing containers.\nContainerization Technology\nDocker and Kubernetes are popular containerization technologies that have transformed application development, deployment, and management.\nDocker simplifies containerization by providing tools to create and run lightweight, isolated containers. Kubernetes focuses on container orchestration, automating deployment, scaling, and management.\nConclusion 🏁\nDon\u0026rsquo;t worry if you are not familiar with Docker and Kubernetes, this blog is just an introduction. We will see upcoming concepts in our later blogs. Hereafter, my focus is mainly on containerization and its technology. If you want to learn containerization with me, you are always welcome. Please subscribe to get regular updates regarding containerization. See you in the next blog. Happy learning 📖\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/exploring-the-world-of-containers/","summary":"Use Container for deployment\nHi friends, welcome back to Blogs-with-Achu! In today\u0026rsquo;s fast-paced technological landscape, containers have emerged as a powerful software development and deployment solution. If you\u0026rsquo;re interested in learning containerization, you don\u0026rsquo;t need any specific prerequisites.😁\nIn Today\u0026rsquo;s Blog:\nWhat is Container?🤔\nWhy it is so popular?🤔\nIs VM?☠️\nContainerization Technology💻\nSummary🏁\n**What is Container?**🤔\nA container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another.","title":"Exploring 🐬the World of Containers"},{"content":"Hi friends, welcome back to Blogs-with-Achu! In my previous blog, we delved into the remarkable world of freeCodeCamp and their extraordinary free courses. Their efforts are truly commendable! Now, in today\u0026rsquo;s exciting blog, I am thrilled to present to you a curated selection of additional YouTube channels that are bound to enhance your study experience. Get ready to embark on an exhilarating journey of knowledge!\nBefore we dive in, let me make it clear that what I\u0026rsquo;m about to share is not promotional in any way. The channels mentioned below reflect my personal interests and ideas, and my goal is to share them so that everyone can benefit from them.\nSome of my favorite YouTube channels ✨\nNetworkChuck\nThinkSchool\nFireship\nTelusko\nTech with Nana\nCloud with raj\nTech with Lucy\nWeb dev simplified\nNetworkChuck⚡ One of my favorite YouTube channels! In this incredible channel, you will immerse yourself in a vast array of network-related concepts, including cloud computing, Docker, Kubernetes, and so much more. The amazing instructor exudes brilliance and his teaching style is deeply captivating. If you\u0026rsquo;re yearning to explore IT concepts in an exhilarating manner, this YouTube channel is an absolute must-watch!\nTo learn more about this channel, visit :https://www.youtube.com/@NetworkChuck\nThinkSchool⚡\nThis YouTube channel is definitely one of my all-time favorites. It offers a fantastic opportunity to delve into the world of business case studies, geopolitical case studies, and other simplified business concepts. I personally admire Ganesh Prasad, one of the brilliant founders of ThinkSchool, who passionately imparts his knowledge through teaching these case studies. What truly sets this channel apart is its accessibility – you don\u0026rsquo;t need to possess any economics background to comprehend the concepts discussed. Trust me when I say that Prasad\u0026rsquo;s teaching style is so straightforward that even a 10-year-old would grasp the content with ease. If delving into the realms of business case studies and geopolitical case studies sparks your interest, then this channel is an absolute goldmine of resources awaiting your exploration.\nTo learn more about this channel, visit : https://www.youtube.com/@ThinkSchool\nFireship⚡\nIf you\u0026rsquo;re tired of watching lengthy videos, I offer you the perfect opportunity to grasp the concepts in just 100 seconds. This channel excels at delivering concise explanations of various topics within this timeframe. Furthermore, you can look forward to receiving the weekly edition of The Code Report. In this channel, you will not only stay updated with the latest tech news but also experience a more enjoyable approach through humor and memes. Get ready to thoroughly enjoy the videos!\nTo learn more about this channel, visit : https://www.youtube.com/@Fireship\nTelusko⚡\nIf you are looking to learn JAVA, I believe this YouTube channel is one of the finest resources for gaining a strong understanding of the language. Led by Navin Reddy, an experienced professional in the field of Java, this channel offers comprehensive tutorials to help you grasp the core concepts. Not only does Navin Reddy provide exceptional Java instruction, but he also offers tutorials for various other programming languages. I highly recommend this channel for expanding your knowledge and staying ahead in your programming journey.\nTo learn more about this channel, visit : https://www.youtube.com/@Telusko\nTech with Nana ⚡\nIf you are eager to gain expertise in the field of DevOps and platform engineering, look no further than this channel! It is specifically curated for individuals like you who want to delve into the intricacies of DevOps concepts. What makes this channel truly unique is its ability to present these complex ideas in a simplified manner, ensuring that even beginners can easily grasp them. So, seize the opportunity to broaden your knowledge and understanding by subscribing to this incredible platform. You won\u0026rsquo;t be disappointed with the quality of education and insights it provides!\nTo learn more about this channel, visit : https://www.youtube.com/@TechWorldwithNana\nCloud with Raj⚡\nRaj, the instructor of this YouTube channel, is currently the Principal Solution Architect at AWS. He possesses extensive expertise in teaching various services in AWS**,** particularly in working with serverless and Kubernetes services. If you are eager to delve into AWS and other concepts, such as Kubernetes, this channel is undoubtedly the best choice for you.\nTo learn more about this channel, visit : https://www.youtube.com/@cloudwithraj\nTech with Lucy⚡\nLucy, a former Solution Architect at AWS, possesses extensive experience in working with AWS. If you are interested in learning AWS, her channel serves as an exceptional resource. Additionally, she currently shares her experiences through her newsletter called \u0026ldquo;Cloudbites.\u0026rdquo; Keep yourself updated with her insights and expertise.\nTo learn more about this channel, visit : https://www.youtube.com/@TechwithLucy\nWeb dev simplified⚡\nThis channel is tailored for individuals who are eager to acquire knowledge in web-related concepts. Kyle, the instructor of this YouTube channel, possesses deep expertise in teaching React. Whether you are interested in mastering React, JavaScript, Node.js, TypeScript, or any other web programming language, this channel is truly exceptional. Kyle effortlessly elucidates each concept in a simplified manner, making the learning experience truly remarkable.\nTo learn more about this channel, visit : https://www.youtube.com/@WebDevSimplified\nConclusion\nHey, hey, hey! You all know the drill! If you\u0026rsquo;ve stumbled upon any other YouTube channels that rock your socks off, drop \u0026rsquo;em in the comment section and let everyone else get a taste of the awesomeness. That\u0026rsquo;s a wrap for today, folks! We\u0026rsquo;ll catch you on the flip side in the next exciting blogs. Until then, keep those brain cells buzzing and soak up all that knowledge. Happy learning, my friends!\nRegards\nAchanandhi M👦\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/my-favourite-youtube-channels/","summary":"Hi friends, welcome back to Blogs-with-Achu! In my previous blog, we delved into the remarkable world of freeCodeCamp and their extraordinary free courses. Their efforts are truly commendable! Now, in today\u0026rsquo;s exciting blog, I am thrilled to present to you a curated selection of additional YouTube channels that are bound to enhance your study experience. Get ready to embark on an exhilarating journey of knowledge!\nBefore we dive in, let me make it clear that what I\u0026rsquo;m about to share is not promotional in any way.","title":"Must-Watch YouTube Channels That Will Blow Your Mind"},{"content":"Hi friends, welcome back to Blogs-with-Achu. In this blog, we are going to see how we can learn Computer science concepts, programming language and leading cutting edge technology related to Computer Science for absolutely free.\nThere are many communities that are providing free courses for learning computer science concepts along with certificates. The communities which I suggested below are based on my opinion. I am currently using these communities for upskills my skills.\nUse YouTube as Your Instructor\nI think the best way to learn any concept regardless of the field, one of the best sources is YouTube. You can see a number of videos and concepts based on your interest. You have the flexibility to learn at your own pace. But the main disadvantage now while learning with YouTube is that it does not provide a certificate for learners. I think in my perspective certificate is not so important, only the skills and knowledge matter.\nfreeCodeCamp - My favorite Instructor\nfreeCodeCamp has separate YouTube channels, and they have separate websites for learning programming languages and even there provide separate certificates after finishing the course.\nIn the above there are many free available course with certificate\nApart from the certificate, the one thing I love is having hands-on experience.\nU can learn the concepts and after learning you have the chance to practice in the same window, I really love this feature. You don\u0026rsquo;t need to pay for anything.\nBasically, freeCodeCamp is a community teaching millions of students to achieve their tech dream.\nApart from teaching there maintain blog pages on their websites, many developers, and working professionals write blogs, especially technical blogs, and u can also read without paying a single dollar or any subscription.\nIn my next blog, we will see other learning platforms. Stay tuned and Happy learning!\nRegards\nAchanandhi M\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/learn-practice-and-succeed-freecodecamp/","summary":"Hi friends, welcome back to Blogs-with-Achu. In this blog, we are going to see how we can learn Computer science concepts, programming language and leading cutting edge technology related to Computer Science for absolutely free.\nThere are many communities that are providing free courses for learning computer science concepts along with certificates. The communities which I suggested below are based on my opinion. I am currently using these communities for upskills my skills.","title":"Learn, Practice, and Succeed-freeCodeCamp"},{"content":"Hi friends, welcome back to Blogs-with-Achu. In my previous blog👈, I mentioned how you can use AI 🤖to upskill, and I also showcased some examples of how you can use ChatGpt for learning📖 Have you ever wondered🤔 how these technologies are developed and which programming language is used to build them? In today\u0026rsquo;s blog, we will explore the programming languages that underpin these cutting-edge innovations.\nIn Today\u0026rsquo;s Blog:\nWhat is a programming language why it is needed?\nPython🐍 for AI\nWriting our First program1️⃣\nWhat is a Programming language?\nImagine you have a robot 🤖friend. To make your robot friend do things, you need to give it instructions. You can\u0026rsquo;t just say, \u0026ldquo;Robot, do something!\u0026rdquo; because the robot won\u0026rsquo;t know what to do. So, you need to speak the robot\u0026rsquo;s language, which is the programming language.\nProgramming languages are needed because computers👨‍💻 are really smart, but they can\u0026rsquo;t understand our regular human language. So, when people write programs using a programming language, they are writing a special set of instructions that the computer can understand. These instructions tell the computer what to do step by step, like playing a game or solving a math problem.\nIn simple words, a programming language is like a secret code that helps us talk to computers and make them do cool things!\nPython for AI\nPython🐍 is a popular language because it\u0026rsquo;s easy to read and write. It\u0026rsquo;s like speaking in a way that both humans and computers can understand. It\u0026rsquo;s a bit like talking 🗣️to a friend. You can say things like \u0026ldquo;print \u0026lsquo;Hello!\u0026rsquo;\u0026rdquo; and the computer💻 will show the word \u0026ldquo;Hello!\u0026rdquo; on the screen.\nPython has gained immense popularity as the language of choice for AI development. Python offers a vast ecosystem of libraries and frameworks specifically designed for AI and machine learning tasks. Popular libraries such as TensorFlow, PyTorch, and scikit-learn provide robust functionality, simplifying complex AI tasks.\nPython has a large⚡ and active community of developers who contribute to open-source AI projects, provide comprehensive tutorials, and offer support.\nThe choice of choosing programming language depends on the technology and the specific requirements of the project.\nWriting our First Program\nI use VSCodium, a popular Integrated Development Environment (IDE), for writing code. In VSCodium, you can write code in various programming languages. It is free and open-source software. Use this link to install VSCodium.\nIn the above ⬆️example, I have written a simple \u0026ldquo;Hello World\u0026rdquo; program, which is commonly used by programmers to start learning a new programming language.\nI created a file called \u0026ldquo;helloworld.py\u0026rdquo; (you can give any Filename) and wrote just one line of code: **print('Hello World')**. This line of code will print \u0026ldquo;Hello World\u0026rdquo; in the terminal.\nRunning a Python🐍 file in the terminal is simple. You can use the command **python yourFilename.py**, and it will execute the code and display the output in the terminal.\nWriting code in Python is similar to having a conversation with a 🚹human. It is easy to learn and understand. This is just an overview of Python, and in my next blog, we will delve into a detailed overview. Stay tuned and Happy learning!\nRegards\nAchanandhi M\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/the-art-of-coding/","summary":"Hi friends, welcome back to Blogs-with-Achu. In my previous blog👈, I mentioned how you can use AI 🤖to upskill, and I also showcased some examples of how you can use ChatGpt for learning📖 Have you ever wondered🤔 how these technologies are developed and which programming language is used to build them? In today\u0026rsquo;s blog, we will explore the programming languages that underpin these cutting-edge innovations.\nIn Today\u0026rsquo;s Blog:\nWhat is a programming language why it is needed?","title":"The Art of Coding"},{"content":"Hi friends, welcome back to Blogs-with-Achu. I believe we are currently experiencing the next revolution ➡️ the AI 🤖Revolution. The excitement surrounding AI has escalated significantly following the release of ChatGpt by OpenAI.\nIn Today\u0026rsquo;s Blog:\nWhat exactly is AI?🤔\nThe marvels of ChatGpt and how it can assist you?🫂\nReal-Time Examples📔\nWhat exactly is AI🤖\nImagine a world🌍 where machines could think🤔, learn, and even outsmart us, humans. Fascinating, right? Well, that\u0026rsquo;s the magic🪄 of AI. AI is a system that thinks and acts like a human. In simple terms, AI is all about teaching computers🖥️ to think and learn in ways similar to ours. AI systems learn from data. Data plays a vital role in creating AI. It uses techniques like Machine Learning, Deep Learning, and other methods to develop AI systems.\n**The marvels of ChatGpt and how it can assist you?**🫂\nChatGpt is an artificial intelligence (AI) chatbot developed by OpenAI and released in November 2022. ChatGpt (Chat Generative Pre-Trained Transformer) is like having a super-smart AI friend who loves to chat and entertain. With ChatGpt, you can ask questions, share stories, and even have it write blogs, essays, and code. You can also utilize it for debugging your code.\nHowever, ChatGpt is not limited to specific use cases like coding. It has a wide range of applications. You can harness its superpower for learning math, commerce, business, medicine, and much more. It can even teach you advanced concepts in various fields.\nRemember, ChatGpt has a huge volume of data stored🫙 in the backend, most likely in the ☁️cloud. The crucial aspect of using ChatGpt effectively lies in how you interact with it. So, how can you ask questions in a way that ensures ChatGpt understands and generates easily understood responses?\nYou will become a master in using ChatGpt once you know how to ask questions. It\u0026rsquo;s similar to how we use Google: we type in the search bar what we are looking for. The same principle applies to ChatGpt, with the difference being that Google is a search engine while ChatGpt engages in human-like conversations(chat bot).\nNo need to worry if it sounds complicated! Let\u0026rsquo;s make understanding ChatGpt easy and fun by exploring some examples together🙌. If you\u0026rsquo;re already using this incredible superpower, feel free to share your experiences and tips in the comments section below. 👇\nReal time Examples📔\nIf you\u0026rsquo;re a new user and haven\u0026rsquo;t tried ChatGpt yet, click the link to use ChatGpt. ChatGpt has two version\nGPT-3.5 version(free version )\nThe GPT-3.5 version is free to use, which is sufficient for normal users. However, it has limitations in that it can only generate text-based outputs and does not support image generation. The responses generated by GPT-3.5 are typically in text format. GPT-4 version (paid version)🤑\nOn the other hand, the GPT-4 version is an upgraded model with enhanced capabilities. It can work with images and can generate images as well. Additionally, the response time is faster compared to the previous version. However, using the GPT-4 version requires a subscription fee of approximately $20 per month, which is equivalent to around 1650 Indian rupees. **Note: ChatGpt has limited information available up until September 2021. I may not have the latest or most up-to-date information.**🥲\nI think we have discussed enough theories about ChatGpt. Now, let\u0026rsquo;s get hands-on and dive into some practical examples.\nStep 1: Create your account - if your new user 🆕\nStep 2: After creating an account, you enter into a world of magic.🪄\nStep 3: Use the input box to ask questions\nChatGpt can teach Economics\nTips: You can type anything you want to ask, in the above example I want to know about Economics and also not in complex words instead I mentioned explaining in simple terms.\nNow you can see the output it generated - The responses are saved in the left panel⬅️ you can in the left side👈, the responses are auto-saved you don\u0026rsquo;t need to save them manually, it is autosaved and stored in the cloud. If the responses generated are not good, it still confusing you can also regenerate using the regenerate response.\nPro-Tips: Ask questions like \u0026ldquo;Explain it for age 5\u0026rdquo;, \u0026ldquo;Explain in simple terms\u0026rdquo;, and \u0026ldquo;Explain it with simple examples \u0026ldquo;. Remember if you misspelled the word \u0026ldquo;Economics,\u0026rdquo; ChatGpt still generates the correct output. So don\u0026rsquo;t worry about mistakes, ChatGpt can still generate correct output.\nIn the above example, I asked ChatGpt to explain economics to a 5-year-old, and it magically generated a response that was easy to understand. It\u0026rsquo;s truly a magical experience! Try it out for yourself and let me know in the comments section how your experience was while working with ChatGpt.\nNote: ChatGpt is not limited to specific areas. I am just showcasing examples in certain fields to demonstrate its capabilities.\nChatGpt can Write Code👨‍💻\nFor computer science students, writing code is an important task. ChatGpt can assist in generating code, and it does so in a way that is easy to understand.\nIn the above examples, I mentioned writing code in Python to say \u0026ldquo;hello world.\u0026rdquo; Even though I misspelled the word \u0026ldquo;Python,\u0026rdquo; ChatGpt still generated the correct output. It showcases the impressive capability of ChatGpt to handle human errors and generate accurate results.\nChatGpt can assist with Debugging\nDebugging🪲 is one of the important tasks for programmers. Let\u0026rsquo;s see how ChatGpt performs in this aspect and generates output that helps in debugging.\nIn the above example, I wrote code in Python utilizing OOP concepts. However, I encountered struggles as my code was not generating the expected output. To resolve this, I turned to ChatGpt for debugging assistance.\nIn the above example, the images showcase the updated version of my code, along with a detailed explanation highlighting the mistakes I made.\nI think we have covered a lot🕗 about ChatGpt and explored some examples. If you want to experience the superpower💪 of ChatGpt for guidance and mentoring, feel free to use it and share your experience in the comments section. I would also appreciate any suggestions you have regarding my blog. If you found it useful, please🙏 share it with your friends🧑‍🤝‍🧑 so they can also benefit from this incredible tool. This is just an overview of how you can utilize ChatGpt, and in my next blog⏭️, we will delve into a detailed overview. Stay tuned, and happy learning📖!\nRegards\nAchanandhi M\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/magic-of-chatgpt/","summary":"Hi friends, welcome back to Blogs-with-Achu. I believe we are currently experiencing the next revolution ➡️ the AI 🤖Revolution. The excitement surrounding AI has escalated significantly following the release of ChatGpt by OpenAI.\nIn Today\u0026rsquo;s Blog:\nWhat exactly is AI?🤔\nThe marvels of ChatGpt and how it can assist you?🫂\nReal-Time Examples📔\nWhat exactly is AI🤖\nImagine a world🌍 where machines could think🤔, learn, and even outsmart us, humans. Fascinating, right?","title":"Magic of ChatGpt"},{"content":" Welcome,👋folks! I think every one of you heard about AWS(Amazon Web Services). In 2006, Amazon launched Amazon Web Services (AWS) as a way to provide cloud computing services to businesses🏢 and individuals.\nAbout Today Blog post:\nOverview of AWS.\nList of Services from AWS.\nFree Resources to learn AWS.\nUse Chatgpt for Learning.\nOverview of AWS\nAWS is one of the widely used cloud computing☁️ platforms. It offers a vast array of services that enable businesses, developers, and individuals to build🏗️ and deploy applications, store🫙 and manage data, and leverage powerful💪 computing resources on a pay-as-you-go💵 basis.\nList of Services from AWS\nInitially, AWS offered basic services like storage🫙 and computing power, but it quickly expanded its offerings to include various other services, such as databases, networking, and developer tools. As of now, AWS is providing 200+ services for various use cases, choose the best one that suits your business.\nAmazon EC2 (Elastic Compute Cloud): Provides virtual servers in the cloud, allowing users to scale computing resources as needed.\nAmazon S3 (Simple Storage Service): Scalable object storage for storing and retrieving data, often used for backup, static website hosting, and data archiving.\nAWS Lambda(Serverless): Allows users to run code without provisioning or managing servers, enabling serverless computing and event-driven architectures.\nAmazon RDS (Relational Database Service): Managed relational database service supporting various database engines like MySQL, PostgreSQL, and Oracle.\nAmazon DynamoDB: A fully managed NoSQL database service that offers high scalability, low latency, and automatic scaling.\nAmazon CloudFront: Content delivery network (CDN) for fast and secure delivery of data, videos, applications, and APIs.\nAmazon VPC (Virtual Private Cloud): Enables users to create an isolated virtual network in the cloud and launch AWS resources within it, providing enhanced security and control.\nAmazon SNS (Simple Notification Service): A messaging service for sending push notifications to mobile devices, email notifications, and more.\nAmazon SQS (Simple Queue Service): Fully managed message queuing service for decoupling and scaling microservices, distributed systems, and serverless applications.\nAWS S3 Glacier: Low-cost storage service for long-term data archiving and backup purposes.\nAmazon ECS(Elastic Container Service):ECS is a fully managed container orchestration service that allows you to run and scale containerized applications.\nAmazon EKS(Elastic Kubernetes Service): Amazon EKS is a managed Kubernetes service that simplifies the deployment, management, and scaling of Kubernetes clusters.\nThese are just a few examples, and there are many more AWS services available to cater to various needs such as machine learning, analytics, security, IoT, and more.\nYou can also use Cloud Environment for running🏃‍♂️ your Machine learning models and also u can deploy our machine learning models into the cloud.☁️\nAmazon Sage maker is the famous ML Service offered by AWS. It simplifies the process of building, training, and deploying ML models at scale.📈\nThe tech industry growing day by day, Last month \u0026ldquo;AWS announced\u0026rdquo; Amazon Bedrock and Amazon CodeWhisperer. Amazon CodeWhisperer is like an alternative to GitHub Copilot it can write code for you in your code editor, U can use it for free🆓 of cost, and u can also perform security scans in your code. If you want to try it out click this link\nFree Resources for Learning AWS\nAWS Skill Builder - A learning platform designed by AWS, for learning cloud. By signing up, you get free access to 500+ courses available.\nAWS Free tier-Experiment and practice with AWS at no cost. The Free Tier provides limited free access to a range of AWS services.\nAWS Cloud Quest- cloud quest is an interactive game-based learning experience that guides your cloud career development. After finishing you will receive a quest badge and an offer for writing an AWS Cloud partitioner exam, considered one of the basic level certification exams in the cloud industry.\nApart from that, AWS also offerings many workshops and live training you can also make use of it.\nUse Chatgpt for Learning🏫\nYou can also use some other AI tools for learning cloud and other stuff. Chatgpt is the best one among other AI tools, but the main drawback is that it has Limited knowledge😓 of the world and events after 2021. If you want to learn new tools or technology u can use their own documentation for learning. Chatgpt is one kind of superpower💪, if you know how to use it then you are the master. In my next⏭️ blog, I can explain how u can use Chatgpt for learning, how u can use Chatgpt for fixing bugs🪲, how Chatgpt helps other domains, And also the dark 😈side of Chatgpt. See you Next in Blog😊. Happy Learning📖\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/unveiling-the-aws-kingdom/","summary":"Welcome,👋folks! I think every one of you heard about AWS(Amazon Web Services). In 2006, Amazon launched Amazon Web Services (AWS) as a way to provide cloud computing services to businesses🏢 and individuals.\nAbout Today Blog post:\nOverview of AWS.\nList of Services from AWS.\nFree Resources to learn AWS.\nUse Chatgpt for Learning.\nOverview of AWS\nAWS is one of the widely used cloud computing☁️ platforms. It offers a vast array of services that enable businesses, developers, and individuals to build🏗️ and deploy applications, store🫙 and manage data, and leverage powerful💪 computing resources on a pay-as-you-go💵 basis.","title":"Unveiling the AWS Kingdom👑"},{"content":"Let\u0026rsquo;s Soar into the Cloud 🏃‍♂️\nWelcome, all 😊 to this exciting journey into the world of cloud computing. In my previous⏮️blog, I explained what is cloud computing with some examples and its advantages. If you are new🆕to this blog, I strongly recommend seeing my ⏮️previous blog The Magic of the Cloud ☁️🪄 In the upcoming blog, We are about to explore one of the world\u0026rsquo;s leading cloud service providers☁️\nBefore moving further, In my previous blog I have forgotten to mention the two important concepts of cloud computing, first, we will see about that, then we will move to today\u0026rsquo;s topic.\nThe first 1️⃣concept which I need to mention is the types of cloud computing, There are three main types of cloud computing\nPublic cloud 📢\nPrivate cloud 🔏\nHybrid cloud 📢 + 🔏\nPublic cloud- In a Public cloud where resources and services are shared among multiple users and organizations over the internet\nPrivate cloud - In a private cloud where resources and services are dedicated to a single organization or user, providing more control and security.\nHybrid cloud - Hybrid cloud combines both public and private cloud environments\nThe second 2️⃣ concept which I need to mention is the types of services ⚒️models, There are three main types of service model in cloud computing\nPlatform as a service(PaaS)\nInfrastructure as a service(IaaS)\nSoftware as a service(SaaS)\nIaaS - Infrastructure as a Service provides you the flexibility to manage your infrastructure and control your IT resource. You can choose the operating system, networking, and storage by yourself.\nPaaS- In platform as a Service removes the need for organizations🏢 to manage the underlying infrastructure (usually hardware and operating systems) and allows you to focus on deploying and managing your applications.\nSaaS- Software as a Service provides you with a completed product that is run 🏃‍♂️and managed by the service provider. SaaS is like using the software directly without installing it on your own computer🖥️.\nIn Upcoming blogs, we are about to explore one of the world\u0026rsquo;s leading cloud providers, and how as an individual we can learn the service provided by them, In my next blog I will share the Free cloud computing courses and free🆓 hands-on lab. In my upcoming blogs, I am interested to write basics concepts in Python and shell scripting also apart from that I can explain concepts with code and my code will be available on my GitHub profile.\nAre you eager to explore? Don\u0026rsquo;t miss out on my latest blogs Subscribe now and embark on a journey of learning and practicing. Will you see me at the Next one :) 😊\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/taking-your-journey-to-new-heights%EF%B8%8F/","summary":"Let\u0026rsquo;s Soar into the Cloud 🏃‍♂️\nWelcome, all 😊 to this exciting journey into the world of cloud computing. In my previous⏮️blog, I explained what is cloud computing with some examples and its advantages. If you are new🆕to this blog, I strongly recommend seeing my ⏮️previous blog The Magic of the Cloud ☁️🪄 In the upcoming blog, We are about to explore one of the world\u0026rsquo;s leading cloud service providers☁️","title":"Taking Your Journey to New Heights✈️"},{"content":"Welcome back again🥳 , Cloud Computing☁️ is one of the leading cutting edge technology in the IT Industry🔥\nCloud Computing is all about renting IT resources, Let me explain with an example. If you\u0026rsquo;re going to start an IT company🏢, you need some resources like servers (for hosting your website) databases(for Storing data), and along with some stuff, but in the real-world🌎 purchasing IT resources can give a burden to the startup ecosystem and also to other company because of its establishment and maintenance charge.\nNote: The IT resources may include storage, computing power, networking capabilities, and software services.\nBut for now, we can see examples related to servers, Servers are also considered IT resources.\nThe server is like our normal computer, we can also set up our normal computer as a server, but the disadvantage is that it cannot handle huge traffic⛔ because of this processing capability.\nNote: The term Processing capability here refers to the processor(CPU)\nOur normal computers🖥️ have a good amount of processing power which is foremost better for our day-to-day activity, but it is not suitable for large infrastructure.\nTo overcome this issue companies can buy and set up their own infrastructure with computers that have high processing capabilities referred to as servers(supercomputers). This supercomputer now handles huge traffic🦾. But Now also there is a problem 😲, wait this time the problem is related to money, Money??🤔. Yeah, the problem is related to money💰 because setting up large infrastructure needs a huge volume of investment.\nEven though you have set up your infrastructure with a minimum of servers, the problem is not solved 🥲, you need to maintain your supercomputer with Electricity and another kind of stuff 24 x7 ⏳for running your businesses over the internet, if your supercomputer lost power or any other problems occur, your lost your connection with your client and soon your needs to purchase another server or your client needs to wait until the problem is solved.\nAlso Scaling 📈 is another problem with traditional infrastructure, say for example your company is popularized all over the country but your infrastructure setup is just meant for providing service to nearby cities, so your company is failed to provide service to people all over the country\nThe Above all problem is overcome by Cloud (it\u0026rsquo;s like magic🪄)\nThe cloud which I mentioned here is that we are not storing or accessing in the actual cloud, we normally use see it in the sky🤣\nInstead, we are borrowing or renting the resources through the Internet with (pay as you go model)\nThis may leads to an questions like\nFrom whom we are buying?\nWhat does mean by pay as yo go model?\nHow they can provide service to us?\nWhat companies are providing these kinds of services?\nBefore Answering all of the above questions let me explain with a simple example\nI think everyone of you heard about OLA🚗, In ola we are not owning any vehicles for riding, Instead we are mainly facing on our trip, the OLA Platforms take care of all kinds of stuff like finding the shortest path, finding the nearby vehicles ,maintaining the vehicles, and providing salary for driver\u0026rsquo;s. we don\u0026rsquo;t have to worry about anything ,Just enjoy the trip that\u0026rsquo;s all.\nThe above example is the same for the cloud, The job of OLA in the above example is replaced in the context of the cloud by some of the cloud providers like AWS, GCP, AZURE, ALIBABA, IBM, ORACLE, and others.\nThe cloud providers maintain the server and other kinds of stuff for you , Is same as we see in the above example of how OLA maintains the riding platform for his customer\nThis really seems like magic🪄, yeah this magic, you don\u0026rsquo;t need to worry about your investment in servers and people for maintaining your infrastructure and electricity kinds of stuff. Instead, this can be done by your cloud provider, for providing this service you need to pay for the service, Likewise in OLA we pay for the service they provide, which This often referred to as (pay as you model), you paying for the resources what you\u0026rsquo;re using.\nOh my God😲, I forgot to say the advantage of cloud computing such as scalability, flexibility, cost saving, etc.\nScalability-Cloud computing provides the flexibility to easily scale your resources up or down based on your needs\nCost savings - Cloud computing allows you to save money by eliminating the need to invest in expensive hardware, infrastructure, and software upfront\nAccessibility- With the cloud, you can access your data and applications from anywhere with an internet connection.\nCloud is everywhere, Everyone is using the cloud, and some of the cloud services which we are using in our day-to-day life are:\nFile storage and sharing : Google drive , Dropbox etc..\nEmail service : Gmail ,yahoo etc..\nSocial Media: platforms like Facebook, Twitter, and Instagram\nStreaming Services: Popular streaming services like Netflix, Amazon Prime Video\nOnline Collaboration Tools: Cloud-based tools such as Google Docs, Microsoft Office 365\nE-commerce Platforms: E-commerce platforms like Amazon, eBay, and Shopify\nWe have explored the fundamentals, advantages, and real-world examples of how the cloud is revolutionizing the IT industry. But this is just the beginning! Cloud computing is a vast and ever-evolving field with new developments and innovations emerging constantly. Stay tuned for upcoming blogs related to cloud computing. Last but not least, In my next blogs I have a surprise gifts for all of you 💯\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/the-magic-of-the-cloud%EF%B8%8F/","summary":"Welcome back again🥳 , Cloud Computing☁️ is one of the leading cutting edge technology in the IT Industry🔥\nCloud Computing is all about renting IT resources, Let me explain with an example. If you\u0026rsquo;re going to start an IT company🏢, you need some resources like servers (for hosting your website) databases(for Storing data), and along with some stuff, but in the real-world🌎 purchasing IT resources can give a burden to the startup ecosystem and also to other company because of its establishment and maintenance charge.","title":"The Magic of the Cloud☁️🪄"},{"content":" The quieter you become, the more you can hear - Baba Ram Dass\nI think every one of us knows who Monk is, A monk is someone who has chosen to live a life of simplicity, self-discipline, and service to others, Now I have a question for all of you who are here, why should we think like a monk? just ask questions of your inner self, see if you want to know how to dominate on the basketball court, you might turn to Michael Jordan if you wanted to innovate, you might investigate Elon Musk, you might study Beyonce to learn how to perform , if you want to be master in an investment you might turn to Warren Buffet. But If you want to train your mind to find peace, calm, and purpose?\n\u0026ldquo;Monks are the experts\u0026rdquo;.\nFirst of all when I heard about the book \u0026ldquo;Think Like a Monk\u0026rdquo; I wondered \u0026ldquo;How could thinking like a monk help me here in the modern world\u0026rdquo;?\nThinking like a monk points to another way of viewing and approaching life. A way of rebellion, detachment, rediscovery, purpose, focus, discipline, and service. The goal of monk thinking is a life free of ego, envy, lust, anxiety, anger, bitterness, and baggage. To my mind, adopting the monk mindset isn\u0026rsquo;t just possible ; it\u0026rsquo;s necessary. We have no other choice. We need to find calm, stillness, and peace.\nMonks come from all sorts of backgrounds. They\u0026rsquo;re people from all sorts of backgrounds who\u0026rsquo;ve chosen to transform themselves.\nMatthieu Ricard -The world\u0026rsquo;s happiest man was a biologist in his former life.\nLord Mahavir who was the founder of Jainism was a former king.\nAdopting a monk mindset is something that anyone can do. We don\u0026rsquo;t need to go to the ashram for practicing monk mind. The key is to adopt the right mindset.\nI already suggested in my previous post for reading \u0026ldquo;Think Like a Monk\u0026rdquo; book for finding true purpose in our life and also the book explains the importance of meditation.\nStay tuned for more insights on Think Like a Monk and philosophical concepts. I\u0026rsquo;ll be sharing more soon!\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/the-road-to-enlightenment/","summary":"The quieter you become, the more you can hear - Baba Ram Dass\nI think every one of us knows who Monk is, A monk is someone who has chosen to live a life of simplicity, self-discipline, and service to others, Now I have a question for all of you who are here, why should we think like a monk? just ask questions of your inner self, see if you want to know how to dominate on the basketball court, you might turn to Michael Jordan if you wanted to innovate, you might investigate Elon Musk, you might study Beyonce to learn how to perform , if you want to be master in an investment you might turn to Warren Buffet.","title":"The Road to Enlightenment🚶"},{"content":"Hi there, my name is Achanandhi M and like many of you, I\u0026rsquo;ve been on a journey of self-discovery. I am so grateful for my life. When I reflect on all the wonderful people and experiences that have shaped who I am today, I am filled with a deep sense of gratitude. And at the top of the list of people I am grateful for are my parents. They have been a constant source of love, support, and wisdom throughout my life, and I am incredibly lucky to have them.\nEducation has always been a top priority for me, My career in Computer Science has been fulfilling and challenging, and I\u0026rsquo;m grateful for the opportunities I\u0026rsquo;ve had to learn and grow in this field.\nWhen I\u0026rsquo;m not working, I enjoy reading books on philosophy and spirituality, practicing yoga, playing badminton and listening to music. These hobbies help me stay centered and connected to my inner self, and they\u0026rsquo;re an essential part of who I am.\nBelow are two things that I learned from my own experiences and from my guru (Jay Shetty)Who inspired me a lot from his called \u0026ldquo;THINK LIKE A MONK\u0026rdquo;, I suggest everyone read this book for finding their true purpose in your life\nWhen you start comparing with others, you definitely lose your true identity, so please don\u0026rsquo;t compare yourself with others, everyone has a different clock.\n. I have no doubt that \u0026ldquo;Service is the direct path to a meaningful life\u0026rdquo; and the true meaning of life is making a difference in the lives of others.\nI have planned to write blogs on philosophy, open source, technology related to DevOps, cloud computing, web development, Linux, and some valuable Lessons from great Books like THINK LIKE A MONK, 5 AM CLUB,8 THINGS OF LOVE, etc.\nLet\u0026rsquo;s stay connected and continue this conversation by subscribing to my blog for regular updates.\n","permalink":"https://mellow-biscuit-c19821.netlify.app/blog/who-am-i/","summary":"Hi there, my name is Achanandhi M and like many of you, I\u0026rsquo;ve been on a journey of self-discovery. I am so grateful for my life. When I reflect on all the wonderful people and experiences that have shaped who I am today, I am filled with a deep sense of gratitude. And at the top of the list of people I am grateful for are my parents. They have been a constant source of love, support, and wisdom throughout my life, and I am incredibly lucky to have them.","title":"Who am I🤔"},{"content":"This project is based on Flask. The flask server is deployed in the (Amazon EC2) the flask serves the HTML form, and when the user enters the data in the form the data will be stored inside Amazon RDS(Database) 🔗 GitHub Table of Contents Features Installation Usage Dependencies Contributing Features User Input Form: Users can submit their name, favorite quote, and advice through a form. Database Integration: Data submitted by users is stored in a PostgreSQL database hosted on Amazon RDS. Dynamic Responses: After submitting the form, users are redirected to a response page where they can see a confirmation message. Installation To run this project locally, follow these steps:\nClone the repository:\ngit clone https://github.com/Achanandhi-M/AWS-TwoTier-application.git Navigate to the project directory:\ncd AWS-TwoTier-application Install the required dependencies:\npip install -r requirements.txt Run the Flask application:\npython3 app.py Open your web browser and go to http://localhost:5000/ to access the application.\nUsage Fill out the form with your name, favorite quote, and advice. Click the \u0026ldquo;Submit\u0026rdquo; button to submit the form. You will be redirected to a response page where you can see a confirmation message. Dependencies Flask: Flask is a lightweight WSGI web application framework in Python. psycopg2: psycopg2 is a PostgreSQL adapter for the Python programming language. Contributing Contributions are welcome! If you\u0026rsquo;d like to contribute to this project, please fork the repository and submit a pull request.\n","permalink":"https://mellow-biscuit-c19821.netlify.app/projects/aws-two-tier-application/","summary":"This project is based on Flask. The flask server is deployed in the (Amazon EC2) the flask serves the HTML form, and when the user enters the data in the form the data will be stored inside Amazon RDS(Database) 🔗 GitHub Table of Contents Features Installation Usage Dependencies Contributing Features User Input Form: Users can submit their name, favorite quote, and advice through a form. Database Integration: Data submitted by users is stored in a PostgreSQL database hosted on Amazon RDS.","title":"AWS Two tier Application"},{"content":"This project demonstrates how to automate the deployment pipeline of a web application using Jenkins, Git, and Docker. The final Docker image is uploaded to an Amazon EC2 instance for deployment.\n🔗 GitHub Table of Contents Overview Prerequisites Setup Jenkins Configuration Git Repository Setup Docker Image Creation Continuous Integration/Continuous Deployment (CI/CD) Deploying to Amazon EC2 Contributing License Overview In this project, we aim to automate the deployment process of a web application. The pipeline involves the following steps:\nCode is pushed to a Git repository. Jenkins monitors the repository and triggers a build when changes are detected. Jenkins builds a Docker image of the web application. The Docker image is pushed to a Docker registry. An Amazon EC2 instance pulls the Docker image and deploys the application. Prerequisites Before setting up the CI/CD pipeline, make sure you have the following prerequisites installed:\nJenkins Git Docker AWS Account (for Amazon EC2) Setup Jenkins Configuration Install Jenkins on your server or machine. Configure Jenkins to work with your Git repository. Set up Jenkins to build the project whenever changes are pushed to the repository. Git Repository Setup Create a Git repository to host your web application code. Add a webhook in your Git repository settings to notify Jenkins on code changes. Docker Image Creation Write a Dockerfile to describe the web application\u0026rsquo;s containerization. Create a Jenkins job to build the Docker image and push it to a Docker registry (e.g., Docker Hub). Continuous Integration/Continuous Deployment (CI/CD) This project focuses on automating the CI/CD pipeline with Jenkins. The pipeline includes:\nCode integration from Git. Building a Docker image. Pushing the Docker image to a registry. To customize and set up your Jenkins pipeline, refer to the Jenkins documentation and create Jenkins pipeline scripts.\nDeploying to Amazon EC2 Set up an Amazon EC2 instance with Docker installed. Pull the Docker image from your Docker registry. Run the Docker container on your EC2 instance. Contributing We welcome contributions to this project. Please feel free to submit issues, pull requests, or provide suggestions for improvement.\nLicense This project is licensed under the MIT License.\n","permalink":"https://mellow-biscuit-c19821.netlify.app/projects/cd-automation-with-jenkins-git-and-docker/","summary":"This project demonstrates how to automate the deployment pipeline of a web application using Jenkins, Git, and Docker. The final Docker image is uploaded to an Amazon EC2 instance for deployment.\n🔗 GitHub Table of Contents Overview Prerequisites Setup Jenkins Configuration Git Repository Setup Docker Image Creation Continuous Integration/Continuous Deployment (CI/CD) Deploying to Amazon EC2 Contributing License Overview In this project, we aim to automate the deployment process of a web application.","title":"Web Application CI/CD Automation with Jenkins, Git, and Docker"},{"content":"This repository contains the source code and configuration for a simple web application and a Continuous Integration / Continuous Deployment (CI/CD) pipeline using AWS services, including AWS CodePipeline, AWS CodeBuild, and AWS Elastic Beanstalk.\n🔗 GitHub Table of Contents Overview Requirements Getting Started Prerequisites Setup Pipeline Stages Automated Testing Deployment Contributing License Output Overview The primary goal of this project is to set up a CI/CD pipeline that automates the build, test, and deployment of a simple web application to AWS Elastic Beanstalk whenever changes are pushed to the repository. Below are the key components of the project:\nWeb Application: A simple web application that is hosted on AWS Elastic Beanstalk.\nCI/CD Pipeline: The CI/CD pipeline is defined using AWS CodePipeline and includes the following stages:\nSource: Pulls the code from the repository. Build: Builds the application using AWS CodeBuild. Deploy: Deploy the application to Elastic Beanstalk using CodePipeline to Elastic Beanstalk integration. Requirements To set up and use this CI/CD pipeline, you need the following requirements:\nAn AWS account with the necessary permissions. An AWS Elastic Beanstalk environment for hosting the web application. A GitHub repository to host the source code. An AWS CodeBuild project for building the application. Getting Started Prerequisites Before you start, ensure you have the following prerequisites:\nAWS account credentials configured on your local machine. AWS CLI and AWS Elastic Beanstalk CLI (EB CLI) installed. GitHub repository with your web application code. Setup Create a GitHub Repository: Create a new repository for your web application on GitHub.\nConfigure AWS Services:\nSet up an AWS Elastic Beanstalk environment to host your application. Create an AWS CodeBuild project for building your application. Create AWS CodePipeline:\nSet up an AWS CodePipeline that defines the source, build, and deploy stages. Configure Automatic Trigger:\nConfigure the pipeline to be triggered automatically whenever there is a change to the code in your GitHub repository. Deploy the Pipeline:\nDeploy the configured pipeline in AWS. Pipeline Stages The CI/CD pipeline is composed of the following stages:\nSource Stage:\nThis stage pulls the code from your GitHub repository whenever changes are pushed. Build Stage:\nThis stage builds the application using AWS CodeBuild, ensuring that your application is ready for deployment. Deploy Stage:\nThis stage deploys the application to the Elastic Beanstalk environment using CodePipeline\u0026rsquo;s integration. Automated Testing You can add automated tests to your application and configure the pipeline to run these tests before deploying the application.\nDeployment Your web application will be automatically built, tested (if configured), and deployed to AWS Elastic Beanstalk whenever changes are pushed to your GitHub repository.\nContributing We welcome contributions to this project. Please feel free to submit issues, feature requests, or pull requests.\nLicense This project is licensed under the MIT License.\nOutput(For Reference) Configure the Environment for Elastic Beanstalk Choose the platform and platform Branch based on your requirements, This project is based on Nodejs Set up the Networking and Database Configure Pipeline for CI/CD Choose the pipeline Settings Most importantly add source providers like(Github , BitBucket, Codecommit etc) Create a Build stage in the Codebuild Service console Add Build Stage Add deploy Stage Finally Review the Changes and click Create Logs Complete Flowchart ElaticBeanStalk Console Click the Domain link to access the web application Final output of the Web Application Happy coding and automating your deployments with AWS! 😊\n","permalink":"https://mellow-biscuit-c19821.netlify.app/projects/cd-pipeline-for-web-application-with-elastic-beanstalk/","summary":"This repository contains the source code and configuration for a simple web application and a Continuous Integration / Continuous Deployment (CI/CD) pipeline using AWS services, including AWS CodePipeline, AWS CodeBuild, and AWS Elastic Beanstalk.\n🔗 GitHub Table of Contents Overview Requirements Getting Started Prerequisites Setup Pipeline Stages Automated Testing Deployment Contributing License Output Overview The primary goal of this project is to set up a CI/CD pipeline that automates the build, test, and deployment of a simple web application to AWS Elastic Beanstalk whenever changes are pushed to the repository.","title":""},{"content":"Python-todo-application 🔗 GitHub Getting started To make it easy for you to get started with GitLab, here\u0026rsquo;s a list of recommended next steps.\nAlready a pro? Just edit this README.md and make it your own. Want to make it easy? Use the template at the bottom!\nAdd your files Create or upload files Add files using the command line or push an existing Git repository with the following command: cd existing_repo git remote add origin https://gitlab.com/achanandhi.m/python-todo-application.git git branch -M main git push -uf origin main Integrate with your tools Set up project integrations Collaborate with your team Invite team members and collaborators Create a new merge request Automatically close issues from merge requests Enable merge request approvals Set auto-merge Test and Deploy Use the built-in continuous integration in GitLab.\nGet started with GitLab CI/CD Analyze your code for known vulnerabilities with Static Application Security Testing (SAST) Deploy to Kubernetes, Amazon EC2, or Amazon ECS using Auto Deploy Use pull-based deployments for improved Kubernetes management Set up protected environments Editing this README When you\u0026rsquo;re ready to make this README your own, just edit this file and use the handy template below (or feel free to structure it however you want - this is just a starting point!). Thanks to makeareadme.com for this template.\nSuggestions for a good README Every project is different, so consider which of these sections apply to yours. The sections used in the template are suggestions for most open source projects. Also keep in mind that while a README can be too long and detailed, too long is better than too short. If you think your README is too long, consider utilizing another form of documentation rather than cutting out information.\nName Choose a self-explaining name for your project.\nDescription Let people know what your project can do specifically. Provide context and add a link to any reference visitors might be unfamiliar with. A list of Features or a Background subsection can also be added here. If there are alternatives to your project, this is a good place to list differentiating factors.\nBadges On some READMEs, you may see small images that convey metadata, such as whether or not all the tests are passing for the project. You can use Shields to add some to your README. Many services also have instructions for adding a badge.\nVisuals Depending on what you are making, it can be a good idea to include screenshots or even a video (you\u0026rsquo;ll frequently see GIFs rather than actual videos). Tools like ttygif can help, but check out Asciinema for a more sophisticated method.\nInstallation Within a particular ecosystem, there may be a common way of installing things, such as using Yarn, NuGet, or Homebrew. However, consider the possibility that whoever is reading your README is a novice and would like more guidance. Listing specific steps helps remove ambiguity and gets people to using your project as quickly as possible. If it only runs in a specific context like a particular programming language version or operating system or has dependencies that have to be installed manually, also add a Requirements subsection.\nUsage Use examples liberally, and show the expected output if you can. It\u0026rsquo;s helpful to have inline the smallest example of usage that you can demonstrate, while providing links to more sophisticated examples if they are too long to reasonably include in the README.\nSupport Tell people where they can go to for help. It can be any combination of an issue tracker, a chat room, an email address, etc.\nRoadmap If you have ideas for releases in the future, it is a good idea to list them in the README.\nContributing State if you are open to contributions and what your requirements are for accepting them.\nFor people who want to make changes to your project, it\u0026rsquo;s helpful to have some documentation on how to get started. Perhaps there is a script that they should run or some environment variables that they need to set. Make these steps explicit. These instructions could also be useful to your future self.\nYou can also document commands to lint the code or run tests. These steps help to ensure high code quality and reduce the likelihood that the changes inadvertently break something. Having instructions for running tests is especially helpful if it requires external setup, such as starting a Selenium server for testing in a browser.\nAuthors and acknowledgment Show your appreciation to those who have contributed to the project.\nLicense For open source projects, say how it is licensed.\nProject status If you have run out of energy or time for your project, put a note at the top of the README saying that development has slowed down or stopped completely. Someone may choose to fork your project or volunteer to step in as a maintainer or owner, allowing your project to keep going. You can also make an explicit request for maintainers.\n","permalink":"https://mellow-biscuit-c19821.netlify.app/projects/-python-todo-application/","summary":"Python-todo-application 🔗 GitHub Getting started To make it easy for you to get started with GitLab, here\u0026rsquo;s a list of recommended next steps.\nAlready a pro? Just edit this README.md and make it your own. Want to make it easy? Use the template at the bottom!\nAdd your files Create or upload files Add files using the command line or push an existing Git repository with the following command: cd existing_repo git remote add origin https://gitlab.","title":"Python-todo-application"},{"content":"AWS boto3 Repository 🔗 GitHub Welcome to the AWS Repository! This repository is designed to help you work with Amazon Web Services (AWS) and leverage its powerful cloud computing services.\nGetting Started Prerequisites Before you begin, ensure that you have the following prerequisites installed:\nAWS CLI - Command-line tool for interacting with AWS services AWS SDKs - SDKs for your preferred programming language (e.g., Python, Java, Node.js) Configure your AWS credentials before working with boto3 Installation Clone this repository:\ngit clone https://github.com/Achanandhi-M/aws-boto3.git cd aws-boto3 Set up your AWS credentials using the AWS CLI:\naws configure ","permalink":"https://mellow-biscuit-c19821.netlify.app/projects/-aws-boto3-project-/","summary":"AWS boto3 Repository 🔗 GitHub Welcome to the AWS Repository! This repository is designed to help you work with Amazon Web Services (AWS) and leverage its powerful cloud computing services.\nGetting Started Prerequisites Before you begin, ensure that you have the following prerequisites installed:\nAWS CLI - Command-line tool for interacting with AWS services AWS SDKs - SDKs for your preferred programming language (e.g., Python, Java, Node.js) Configure your AWS credentials before working with boto3 Installation Clone this repository:","title":"AWS  boto3 project"},{"content":"Static-website-in-K8s 🔗 GitHub Deploying our custom website inside k8s using k8s object \u0026ldquo;deployment\u0026rdquo; and \u0026ldquo;service\u0026rdquo;\nI created my own docker image\nAfter creation, I used my docker images to deploy inside k8s using service and deploy.\nMainly I tested this demo using \u0026ldquo;Minkube\u0026rdquo;, You can try this anywhere\nCommands used for me in Minikube\nMinikube start- For starting minikube in a local machine\nMinikube status - For checking the status of Minkube\nkubectl get pods - To list No pods in the cluster\nkubectl get deploy - To list the deployment\nkubectl get service - To list the service\nkubectl create -f - Useful for creation of deployment file\nkubectl create -f - Useful for creation of service file\nMinikube service - Useful for accessing service inside the cluster\n","permalink":"https://mellow-biscuit-c19821.netlify.app/projects/static-website-in-k8s/","summary":"Static-website-in-K8s 🔗 GitHub Deploying our custom website inside k8s using k8s object \u0026ldquo;deployment\u0026rdquo; and \u0026ldquo;service\u0026rdquo;\nI created my own docker image\nAfter creation, I used my docker images to deploy inside k8s using service and deploy.\nMainly I tested this demo using \u0026ldquo;Minkube\u0026rdquo;, You can try this anywhere\nCommands used for me in Minikube\nMinikube start- For starting minikube in a local machine\nMinikube status - For checking the status of Minkube","title":"Static-website-in-K8s"},{"content":"Server-in-Nodejs 🔗 GitHub Creating a simple server using nodejs(javascript run time env) and express for handling request The node js image is built by using Dockerfile Use Dockerfile for Building custom Node js image The Dockerfile uses Latest Node version:18 Use Alphine for Lite version of Node Alphine images are lightweight because they are based on the Alphine Linux distribution\nCode is available in the above github repo link\n","permalink":"https://mellow-biscuit-c19821.netlify.app/projects/server-in-nodejs/","summary":"Server-in-Nodejs 🔗 GitHub Creating a simple server using nodejs(javascript run time env) and express for handling request The node js image is built by using Dockerfile Use Dockerfile for Building custom Node js image The Dockerfile uses Latest Node version:18 Use Alphine for Lite version of Node Alphine images are lightweight because they are based on the Alphine Linux distribution\nCode is available in the above github repo link","title":"Server-in-Nodejs"},{"content":" Developing and maintaining the web applications to meet client requirements, ensuring functionality and usability.\nCollaborated with cross-functional teams to gather project requirements and translate them into technical specifications.\nProvided ongoing support and troubleshooting for website functionality, addressing user inquiries and resolving technical issues promptly.\nTroubleshoot and resolve software defects and issues.\nHere at Itransz, I am learning new things daily. Soon, we are releasing a SAAS product based on Kubernetes. I am very excited about the release and am grateful for the opportunity. Heartfelt thanks to Sarathy Sir and Lakshmi Sir.\n","permalink":"https://mellow-biscuit-c19821.netlify.app/experience/itransz/","summary":"Developing and maintaining the web applications to meet client requirements, ensuring functionality and usability.\nCollaborated with cross-functional teams to gather project requirements and translate them into technical specifications.\nProvided ongoing support and troubleshooting for website functionality, addressing user inquiries and resolving technical issues promptly.\nTroubleshoot and resolve software defects and issues.\nHere at Itransz, I am learning new things daily. Soon, we are releasing a SAAS product based on Kubernetes.","title":"Web Application Intern"}]